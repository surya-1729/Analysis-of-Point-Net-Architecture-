{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# import shutil \n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root = './data', train = True, download = True)\n",
    "test_data = datasets.MNIST(root = './data', train = False, download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------Data Preprocessing --------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Image Data conversion to point cloud  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make data directories\n",
    "# directory = \"classes\"\n",
    "# parent_dir = \"C:/Users/asvp0/Desktop/Happiness/data\"\n",
    "# path = os.path.join(parent_dir, directory)\n",
    "# os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in target_classes:\n",
    "#     i = i\n",
    "#     directory = i    \n",
    "#     parent_dir = \"C:/Users/asvp0/Desktop/Happiness/data/classes\"\n",
    "#     path = os.path.join(parent_dir, directory)\n",
    "#     os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in target_classes:\n",
    "#     i = i\n",
    "#     directory = str(i)\n",
    "#     directory1 = \"train\"\n",
    "#     parent_dir = \"C:/Users/asvp0/Desktop/Happiness/data/classes\"\n",
    "#     path = os.path.join(parent_dir, directory)\n",
    "#     path1 = os.path.join(path, directory1)\n",
    "#     os.mkdir(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in target_classes:\n",
    "#     i = i\n",
    "#     directory = i\n",
    "#     directory1 = \"train\"\n",
    "#     directory2 = \"test\"\n",
    "#     parent_dir = \"C:/Users/asvp0/Desktop/Happiness/data/classes\"\n",
    "#     path = os.path.join(parent_dir, directory)\n",
    "#     path1 = os.path.join(path, directory1)\n",
    "#     path2 = os.path.join(path, directory2)\n",
    "#     os.mkdir(path1)\n",
    "#     os.mkdir(path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image data conversion to point cloud 3 coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(train_data.data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 164)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(int(train_data.data.shape[0] / 60000)):\n",
    "    arr = np.asarray(np.where(train_data.data.numpy()[i] > 1)).T.astype(np.int32)\n",
    "    z = np.zeros((arr.shape[0],1), dtype = int)\n",
    "    arr = np.append(arr, z, axis=1).T\n",
    "#     #print(arr)\n",
    "#     arr = arr.tolist()\n",
    "#     #print(arr)\n",
    "    x, y, z = arr\n",
    "    print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# count = 0\n",
    "# for i in range(train_data.data.shape[0]):\n",
    "#     arr = np.asarray(np.where(train_data.data.numpy()[i] > 1)).T.astype(np.int32)\n",
    "#     z = np.zeros((arr.shape[0],1), dtype = int)\n",
    "#     arr = np.append(arr, z, axis=1)\n",
    "#     list = arr.tolist()\n",
    "#     directory = os.path.abspath(os.path.join(\"C:/Users/asvp0/Desktop/Happiness/data/classes\", str(train_data.targets[i].numpy()), \"train\")).replace(\"\\\\\",\"/\")\n",
    "#     count += 1\n",
    "#     file_name = \"image\" + \"_\" + str(count)\n",
    "#     path = os.path.join(directory, file_name)\n",
    "#     os.remove(path.replace(\"\\\\\",\"/\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(test_data.data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in range(train_data.data.shape[0]):\n",
    "#     arr = np.asarray(np.where(train_data.data.numpy()[i] > 1)).T.astype(np.int32)\n",
    "#     z = np.zeros((arr.shape[0],1), dtype = int)\n",
    "#     arr = np.append(arr, z, axis=1).T\n",
    "#     directory = os.path.abspath(os.path.join(\"C:/Users/asvp0/Desktop/Happiness/data/classes\", str(train_data.targets[i].numpy()), \"train\")).replace(\"\\\\\",\"/\")\n",
    "#     count += 1\n",
    "#     file_name = \"image\" + \"_\" + str(count)\n",
    "#     path = os.path.join(directory, file_name)\n",
    "#     np.savetxt(path, arr, delimiter=',', fmt='%d')\n",
    "# print(count)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point cloud from 2d image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"C:\\\\Users\\\\asvp0\\\\Desktop\\\\Happiness\\\\data\\\\classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read file from the path --> we get point cloud as output here\n",
    "# def readf(file):\n",
    "#     # path = \"C:/Users/asvp0/Desktop/Happiness/data/classes/9/train/image_177\"\n",
    "    \n",
    "#     x, y, z = file.read().splitlines()\n",
    "#     x = [int(i) for i in x.split(',')]\n",
    "#     y = [int(i) for i in y.split(',')]\n",
    "#     z = [int(i) for i in z.split(',')]\n",
    "#     return (x, y, z)\n",
    "\n",
    "# path = \"C:/Users/asvp0/Desktop/Happiness/data/classes/9/train/image_1466\"\n",
    "# file = open(path, \"r\")\n",
    "# x, y, z = readf(file)\n",
    "# print(type(x[9]), type(x), type((x, y, z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = np.zeros((train_data.data.shape[0], 1))\n",
    "# for i in range(10):\n",
    "#     directory = os.path.abspath(os.path.join(\"C:/Users/asvp0/Desktop/Happiness/data/classes\", str(test_data.targets[i].numpy()), \"train\")).replace(\"\\\\\",\"/\")\n",
    "#     for i in directory:\n",
    "        \n",
    "#         np.append(arr, i)\n",
    "#     np.savetxt(path, arr, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display animated rotation of meshes and point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_rotate(data):\n",
    "    x_eye, y_eye, z_eye = 1.25, 1.25, 0.8\n",
    "    frames=[]\n",
    "\n",
    "    def rotate_z(x, y, z, theta):\n",
    "        w = x+1j*y\n",
    "        return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z\n",
    "\n",
    "    for t in np.arange(0, 10.26, 0.1):\n",
    "        xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -t)\n",
    "        frames.append(dict(layout=dict(scene=dict(camera=dict(eye=dict(x=xe, y=ye, z=ze))))))\n",
    "    fig = go.Figure(data=data,\n",
    "                    layout=go.Layout(\n",
    "                        updatemenus=[dict(type='buttons',\n",
    "                                    showactive=False,\n",
    "                                    y=1,\n",
    "                                    x=0.8,\n",
    "                                    xanchor='left',\n",
    "                                    yanchor='bottom',\n",
    "                                    pad=dict(t=45, r=10),\n",
    "                                    buttons=[dict(label='Play',\n",
    "                                                    method='animate',\n",
    "                                                    args=[None, dict(frame=dict(duration=50, redraw=True),\n",
    "                                                                    transition=dict(duration=0),\n",
    "                                                                    fromcurrent=True,\n",
    "                                                                    mode='immediate'\n",
    "                                                                    )]\n",
    "                                                    )\n",
    "                                            ]\n",
    "                                    )\n",
    "                                ]\n",
    "                    ),\n",
    "                    frames=frames\n",
    "            )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_rotate([go.Scatter3d(x=x, y=y, z=z,\n",
    "#                                    mode='markers')]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcshow(xs,ys,zs):\n",
    "    data=[go.Scatter3d(x=xs, y=ys, z=zs,\n",
    "                                   mode='markers')]\n",
    "    fig = visualize_rotate(data)\n",
    "    fig.update_traces(marker=dict(size=2,\n",
    "                      line=dict(width=2,\n",
    "                      color='DarkSlateGrey')),\n",
    "                      selector=dict(mode='markers'))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcshow(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pointcloud =(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize - axis limits change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "        \n",
    "        #np.mean(pointcloud, axis=1)\n",
    "        #np.expand_dims(np.mean(pointcloud, axis=1), axis=-1)\n",
    "        norm_pointcloud = pointcloud - np.expand_dims(np.mean(pointcloud, axis=1), axis=-1)\n",
    "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "\n",
    "        return  norm_pointcloud\n",
    "\n",
    "# norm_pointcloud = Normalize()(pointcloud)\n",
    "# norm_pointcloud.shape\n",
    "# pcshow(*norm_pointcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentations - add random rotation of the whole pointcloud and random noise to its points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandRotation_z(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        theta = random.random() * 2. * math.pi\n",
    "        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
    "                               [ math.sin(theta),  math.cos(theta),    0],\n",
    "                               [0,                             0,      1]])\n",
    "        \n",
    "        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
    "        return  rot_pointcloud\n",
    "    \n",
    "class RandomNoise(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        noise = np.random.normal(0, 0.002, (pointcloud.shape))\n",
    "    \n",
    "        noisy_pointcloud = pointcloud + noise\n",
    "        return  noisy_pointcloud\n",
    "    \n",
    "# rot_pointcloud = RandRotation_z()(norm_pointcloud)\n",
    "# noisy_rot_pointcloud = RandomNoise()(rot_pointcloud)\n",
    "\n",
    "# pcshow(*noisy_rot_pointcloud.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[[3. 3. 1. 2. 1. 3. 3. 3. 2. 3. 3. 2. 1. 2. 2. 3. 3. 1. 3. 1.]]\n"
     ]
    }
   ],
   "source": [
    "target = np.zeros((20, 1))\n",
    "arr = np.array([1, 2, 3])\n",
    "for i in range(0, target.shape[0]):\n",
    "    target[i] = arr[random.randint(0, arr.shape[0]-1)]\n",
    "    i += 1\n",
    "print(arr)    \n",
    "print(target.T)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random.randint(0,9)\n",
    "arr = np.array([1, 2, 3, 4, 5, 6, 7])\n",
    "arr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         small_value = np.random.normal(0, 10e-1, (1,3))     \n",
    "#         random_point = mean_centre + small_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointSampler(object):\n",
    "    np.random.seed = 100000\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, int)\n",
    "        self.output_size = output_size\n",
    "\n",
    "#     def gaussian_random_point(self, mean_centre):\n",
    "#         random_point = np.random.normal(mean_centre, 1, (1,3))\n",
    "#         return random_point\n",
    "    \n",
    "    def __call__(self, pointcloud):\n",
    "        sampled_points = np.zeros((self.output_size, 3))\n",
    "        for i in range(self.output_size):\n",
    "            sampled_points[i] = pointcloud[random.randint(0, pointcloud.T.shape[1] - 1)]\n",
    "            i += 1                   \n",
    "        return sampled_points\n",
    "    \n",
    "# np.random.randint(0, pointcloud.shape[0]-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        #assert len(pointcloud.shape)==2\n",
    "\n",
    "        return torch.from_numpy(pointcloud)\n",
    "# ToTensor()(noisy_rot_pointcloud)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (3, 176)\n"
     ]
    }
   ],
   "source": [
    "# Read file from the path --> we get point cloud as output here\n",
    "def read_file(file):\n",
    "    # path = \"C:/Users/asvp0/Desktop/Happiness/data/classes/9/train/image_177\"\n",
    "    \n",
    "    x, y, z = file.read().splitlines()\n",
    "    x = np.array([int(i) for i in x.split(',')])\n",
    "    y = np.array([int(i) for i in y.split(',')])\n",
    "    z = np.array([int(i) for i in z.split(',')])\n",
    "    return np.vstack((x.T, y.T, z.T))\n",
    "\n",
    "path = Path(\"C:\\\\Users\\\\asvp0\\\\Desktop\\\\Happiness\\\\data\\\\classes\\\\0\\\\train\\\\image_2\")\n",
    "file = open(path, \"r\")\n",
    "pointcloud = read_file(file)\n",
    "print(type(pointcloud), pointcloud.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_transforms():\n",
    "    return transforms.Compose([\n",
    "                                PointSampler(300),\n",
    "                                Normalize(),\n",
    "                                ToTensor()\n",
    "                              ])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudData(Dataset):\n",
    "    def __init__(self, root_dir, valid=False, folder=\"train\" , transform=default_transforms()):\n",
    "        self.root_dir = root_dir\n",
    "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
    "        folders.remove('.ipynb_checkpoints')\n",
    "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
    "        self.transforms = transform if not valid else default_transforms()\n",
    "        self.valid = valid\n",
    "        self.files = []\n",
    "        for category in self.classes.keys():\n",
    "        #if category != '.ipynb_checkpoints':\n",
    "            new_dir = root_dir/Path(category)/folder\n",
    "            for file in os.listdir(new_dir):\n",
    "\n",
    "                sample = {}\n",
    "                sample['pcd_path'] = new_dir/file\n",
    "                sample['category'] = category\n",
    "                self.files.append(sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __preproc__(self, file):\n",
    "        pointcloud = read_file(file)\n",
    "        if self.transforms:\n",
    "            pointcloud = self.transforms(pointcloud.T)\n",
    "        return pointcloud\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pcd_path = self.files[idx]['pcd_path']\n",
    "        category = self.files[idx]['category']\n",
    "        with open(str(pcd_path), 'r') as f:\n",
    "            \n",
    "            pointcloud = self.__preproc__(f)\n",
    "        return {'pointcloud': pointcloud, \n",
    "                'category': self.classes[category]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"C:\\\\Users\\\\asvp0\\\\Desktop\\\\Happiness\\\\data\\\\classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                    PointSampler(300),\n",
    "                    Normalize(),\n",
    "                    RandRotation_z(),\n",
    "                    RandomNoise(),\n",
    "                    ToTensor()\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0',\n",
       " 1: '1',\n",
       " 2: '2',\n",
       " 3: '3',\n",
       " 4: '4',\n",
       " 5: '5',\n",
       " 6: '6',\n",
       " 7: '7',\n",
       " 8: '8',\n",
       " 9: '9'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = PointCloudData(path, transform=train_transforms)\n",
    "valid_ds = PointCloudData(path, valid=True, folder='test', transform = train_transforms)\n",
    "inv_classes = {i: cat for cat, i in valid_ds.classes.items()};\n",
    "inv_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds.__getitem__(1000)['pointcloud'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  60000\n",
      "Valid dataset size:  10000\n",
      "Number of classes:  10\n",
      "Class:  5\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset size: ', len(train_ds))\n",
    "print('Valid dataset size: ', len(valid_ds))\n",
    "print('Number of classes: ', len(train_ds.classes))\n",
    "print('Class: ', inv_classes[train_ds[34772]['category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_fn_padd(batch):\n",
    "#     '''\n",
    "#     Padds batch of variable length\n",
    "\n",
    "#     note: it converts things ToTensor manually here since the ToTensor transform\n",
    "#     assume it takes in images rather than arbitrary tensors.\n",
    "#     '''\n",
    "#     ## get sequence lengths\n",
    "#     lengths = torch.tensor([ t.shape[0] for t in batch ]).to(device)\n",
    "#     ## padd\n",
    "#     batch = [ torch.Tensor(t).to(device) for t in batch ]\n",
    "#     batch = torch.nn.utils.rnn.pad_sequence(batch)\n",
    "#     ## compute mask\n",
    "#     mask = (batch != 0).to(device)\n",
    "#     return batch, lengths, mask\n",
    "\n",
    "# #, collate_fn=collate_fn_padd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # next(iter(train_loader))\n",
    "# trainiter = iter(train_loader)\n",
    "# imgs, labels = trainiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Tnet(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super().__init__()\n",
    "        self.k=k\n",
    "        self.conv1 = nn.Conv1d(k,64,1)\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "        self.fc1 = nn.Linear(1024,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "       \n",
    "\n",
    "    def forward(self, input):\n",
    "        # input.shape == (bs,n,3)\n",
    "        bs = input.size(0)\n",
    "        xb = F.relu(self.bn1(self.conv1(input)))\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "        pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        flat = nn.Flatten(1)(pool)\n",
    "        xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "        xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "\n",
    "        #initialize as identity\n",
    "        init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "        if xb.is_cuda:\n",
    "            init=init.cuda()\n",
    "        matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "        return matrix\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = Tnet(k=3)\n",
    "        self.feature_transform = Tnet(k=64)\n",
    "        self.conv1 = nn.Conv1d(3,64,1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "       \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "       \n",
    "    def forward(self, input):\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        # batch matrix multiplication\n",
    "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
    "\n",
    "        matrix64x64 = self.feature_transform(xb)\n",
    "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = self.bn3(self.conv3(xb))\n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        output = nn.Flatten(1)(xb)\n",
    "        return output, matrix3x3, matrix64x64\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, classes = 10):\n",
    "        super().__init__()\n",
    "        self.transform = Transform()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, classes)\n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
    "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
    "        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
    "        output = self.fc3(xb)\n",
    "        return self.logsoftmax(output), matrix3x3, matrix64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    bs=outputs.size(0)\n",
    "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
    "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n",
    "    if outputs.is_cuda:\n",
    "        id3x3=id3x3.cuda()\n",
    "        id64x64=id64x64.cuda()\n",
    "    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
    "    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n",
    "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnet = PointNet()\n",
    "pointnet.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader=None,  epochs=5, save=True):\n",
    "    for epoch in range(epochs): \n",
    "        pointnet.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "\n",
    "            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:    # print every 10 mini-batches\n",
    "                    print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n",
    "                        (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        pointnet.eval()\n",
    "        correct = total = 0\n",
    "\n",
    "        # validation\n",
    "        if val_loader:\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            val_acc = 100. * correct / total\n",
    "            print('Valid accuracy: %d %%' % val_acc)\n",
    "\n",
    "        # save the model\n",
    "        if save:\n",
    "            torch.save(pointnet.state_dict(), \"save_\"+str(epoch)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1, Batch:   10 / 1875], loss: 2.367\n",
      "[Epoch: 1, Batch:   20 / 1875], loss: 2.319\n",
      "[Epoch: 1, Batch:   30 / 1875], loss: 2.306\n",
      "[Epoch: 1, Batch:   40 / 1875], loss: 2.268\n",
      "[Epoch: 1, Batch:   50 / 1875], loss: 2.211\n",
      "[Epoch: 1, Batch:   60 / 1875], loss: 2.126\n",
      "[Epoch: 1, Batch:   70 / 1875], loss: 2.064\n",
      "[Epoch: 1, Batch:   80 / 1875], loss: 2.114\n",
      "[Epoch: 1, Batch:   90 / 1875], loss: 2.032\n",
      "[Epoch: 1, Batch:  100 / 1875], loss: 1.913\n",
      "[Epoch: 1, Batch:  110 / 1875], loss: 1.991\n",
      "[Epoch: 1, Batch:  120 / 1875], loss: 1.828\n",
      "[Epoch: 1, Batch:  130 / 1875], loss: 1.915\n",
      "[Epoch: 1, Batch:  140 / 1875], loss: 1.868\n",
      "[Epoch: 1, Batch:  150 / 1875], loss: 1.890\n",
      "[Epoch: 1, Batch:  160 / 1875], loss: 1.806\n",
      "[Epoch: 1, Batch:  170 / 1875], loss: 1.780\n",
      "[Epoch: 1, Batch:  180 / 1875], loss: 1.783\n",
      "[Epoch: 1, Batch:  190 / 1875], loss: 1.810\n",
      "[Epoch: 1, Batch:  200 / 1875], loss: 1.740\n",
      "[Epoch: 1, Batch:  210 / 1875], loss: 1.686\n",
      "[Epoch: 1, Batch:  220 / 1875], loss: 1.668\n",
      "[Epoch: 1, Batch:  230 / 1875], loss: 1.703\n",
      "[Epoch: 1, Batch:  240 / 1875], loss: 1.650\n",
      "[Epoch: 1, Batch:  250 / 1875], loss: 1.686\n",
      "[Epoch: 1, Batch:  260 / 1875], loss: 1.597\n",
      "[Epoch: 1, Batch:  270 / 1875], loss: 1.685\n",
      "[Epoch: 1, Batch:  280 / 1875], loss: 1.745\n",
      "[Epoch: 1, Batch:  290 / 1875], loss: 1.581\n",
      "[Epoch: 1, Batch:  300 / 1875], loss: 1.650\n",
      "[Epoch: 1, Batch:  310 / 1875], loss: 1.574\n",
      "[Epoch: 1, Batch:  320 / 1875], loss: 1.661\n",
      "[Epoch: 1, Batch:  330 / 1875], loss: 1.662\n",
      "[Epoch: 1, Batch:  340 / 1875], loss: 1.533\n",
      "[Epoch: 1, Batch:  350 / 1875], loss: 1.515\n",
      "[Epoch: 1, Batch:  360 / 1875], loss: 1.635\n",
      "[Epoch: 1, Batch:  370 / 1875], loss: 1.606\n",
      "[Epoch: 1, Batch:  380 / 1875], loss: 1.549\n",
      "[Epoch: 1, Batch:  390 / 1875], loss: 1.518\n",
      "[Epoch: 1, Batch:  400 / 1875], loss: 1.486\n",
      "[Epoch: 1, Batch:  410 / 1875], loss: 1.411\n",
      "[Epoch: 1, Batch:  420 / 1875], loss: 1.480\n",
      "[Epoch: 1, Batch:  430 / 1875], loss: 1.566\n",
      "[Epoch: 1, Batch:  440 / 1875], loss: 1.469\n",
      "[Epoch: 1, Batch:  450 / 1875], loss: 1.401\n",
      "[Epoch: 1, Batch:  460 / 1875], loss: 1.375\n",
      "[Epoch: 1, Batch:  470 / 1875], loss: 1.470\n",
      "[Epoch: 1, Batch:  480 / 1875], loss: 1.518\n",
      "[Epoch: 1, Batch:  490 / 1875], loss: 1.395\n",
      "[Epoch: 1, Batch:  500 / 1875], loss: 1.429\n",
      "[Epoch: 1, Batch:  510 / 1875], loss: 1.324\n",
      "[Epoch: 1, Batch:  520 / 1875], loss: 1.491\n",
      "[Epoch: 1, Batch:  530 / 1875], loss: 1.333\n",
      "[Epoch: 1, Batch:  540 / 1875], loss: 1.400\n",
      "[Epoch: 1, Batch:  550 / 1875], loss: 1.310\n",
      "[Epoch: 1, Batch:  560 / 1875], loss: 1.321\n",
      "[Epoch: 1, Batch:  570 / 1875], loss: 1.467\n",
      "[Epoch: 1, Batch:  580 / 1875], loss: 1.428\n",
      "[Epoch: 1, Batch:  590 / 1875], loss: 1.399\n",
      "[Epoch: 1, Batch:  600 / 1875], loss: 1.309\n",
      "[Epoch: 1, Batch:  610 / 1875], loss: 1.370\n",
      "[Epoch: 1, Batch:  620 / 1875], loss: 1.212\n",
      "[Epoch: 1, Batch:  630 / 1875], loss: 1.345\n",
      "[Epoch: 1, Batch:  640 / 1875], loss: 1.377\n",
      "[Epoch: 1, Batch:  650 / 1875], loss: 1.369\n",
      "[Epoch: 1, Batch:  660 / 1875], loss: 1.252\n",
      "[Epoch: 1, Batch:  670 / 1875], loss: 1.283\n",
      "[Epoch: 1, Batch:  680 / 1875], loss: 1.306\n",
      "[Epoch: 1, Batch:  690 / 1875], loss: 1.246\n",
      "[Epoch: 1, Batch:  700 / 1875], loss: 1.406\n",
      "[Epoch: 1, Batch:  710 / 1875], loss: 1.332\n",
      "[Epoch: 1, Batch:  720 / 1875], loss: 1.344\n",
      "[Epoch: 1, Batch:  730 / 1875], loss: 1.225\n",
      "[Epoch: 1, Batch:  740 / 1875], loss: 1.264\n",
      "[Epoch: 1, Batch:  750 / 1875], loss: 1.322\n",
      "[Epoch: 1, Batch:  760 / 1875], loss: 1.157\n",
      "[Epoch: 1, Batch:  770 / 1875], loss: 1.352\n",
      "[Epoch: 1, Batch:  780 / 1875], loss: 1.123\n",
      "[Epoch: 1, Batch:  790 / 1875], loss: 1.196\n",
      "[Epoch: 1, Batch:  800 / 1875], loss: 1.314\n",
      "[Epoch: 1, Batch:  810 / 1875], loss: 1.120\n",
      "[Epoch: 1, Batch:  820 / 1875], loss: 1.305\n",
      "[Epoch: 1, Batch:  830 / 1875], loss: 1.200\n",
      "[Epoch: 1, Batch:  840 / 1875], loss: 1.376\n",
      "[Epoch: 1, Batch:  850 / 1875], loss: 1.309\n",
      "[Epoch: 1, Batch:  860 / 1875], loss: 1.230\n",
      "[Epoch: 1, Batch:  870 / 1875], loss: 0.973\n",
      "[Epoch: 1, Batch:  880 / 1875], loss: 1.108\n",
      "[Epoch: 1, Batch:  890 / 1875], loss: 1.151\n",
      "[Epoch: 1, Batch:  900 / 1875], loss: 1.217\n",
      "[Epoch: 1, Batch:  910 / 1875], loss: 1.176\n",
      "[Epoch: 1, Batch:  920 / 1875], loss: 1.117\n",
      "[Epoch: 1, Batch:  930 / 1875], loss: 1.176\n",
      "[Epoch: 1, Batch:  940 / 1875], loss: 1.067\n",
      "[Epoch: 1, Batch:  950 / 1875], loss: 1.146\n",
      "[Epoch: 1, Batch:  960 / 1875], loss: 1.109\n",
      "[Epoch: 1, Batch:  970 / 1875], loss: 1.251\n",
      "[Epoch: 1, Batch:  980 / 1875], loss: 1.087\n",
      "[Epoch: 1, Batch:  990 / 1875], loss: 1.037\n",
      "[Epoch: 1, Batch: 1000 / 1875], loss: 1.262\n",
      "[Epoch: 1, Batch: 1010 / 1875], loss: 1.127\n",
      "[Epoch: 1, Batch: 1020 / 1875], loss: 1.155\n",
      "[Epoch: 1, Batch: 1030 / 1875], loss: 1.073\n",
      "[Epoch: 1, Batch: 1040 / 1875], loss: 0.952\n",
      "[Epoch: 1, Batch: 1050 / 1875], loss: 1.022\n",
      "[Epoch: 1, Batch: 1060 / 1875], loss: 1.080\n",
      "[Epoch: 1, Batch: 1070 / 1875], loss: 1.140\n",
      "[Epoch: 1, Batch: 1080 / 1875], loss: 1.128\n",
      "[Epoch: 1, Batch: 1090 / 1875], loss: 1.135\n",
      "[Epoch: 1, Batch: 1100 / 1875], loss: 1.104\n",
      "[Epoch: 1, Batch: 1110 / 1875], loss: 1.044\n",
      "[Epoch: 1, Batch: 1120 / 1875], loss: 1.029\n",
      "[Epoch: 1, Batch: 1130 / 1875], loss: 1.047\n",
      "[Epoch: 1, Batch: 1140 / 1875], loss: 1.131\n",
      "[Epoch: 1, Batch: 1150 / 1875], loss: 1.045\n",
      "[Epoch: 1, Batch: 1160 / 1875], loss: 1.159\n",
      "[Epoch: 1, Batch: 1170 / 1875], loss: 1.015\n",
      "[Epoch: 1, Batch: 1180 / 1875], loss: 1.140\n",
      "[Epoch: 1, Batch: 1190 / 1875], loss: 1.072\n",
      "[Epoch: 1, Batch: 1200 / 1875], loss: 1.034\n",
      "[Epoch: 1, Batch: 1210 / 1875], loss: 1.009\n",
      "[Epoch: 1, Batch: 1220 / 1875], loss: 0.959\n",
      "[Epoch: 1, Batch: 1230 / 1875], loss: 0.920\n",
      "[Epoch: 1, Batch: 1240 / 1875], loss: 1.006\n",
      "[Epoch: 1, Batch: 1250 / 1875], loss: 0.932\n",
      "[Epoch: 1, Batch: 1260 / 1875], loss: 0.898\n",
      "[Epoch: 1, Batch: 1270 / 1875], loss: 0.986\n",
      "[Epoch: 1, Batch: 1280 / 1875], loss: 0.945\n",
      "[Epoch: 1, Batch: 1290 / 1875], loss: 0.879\n",
      "[Epoch: 1, Batch: 1300 / 1875], loss: 0.995\n",
      "[Epoch: 1, Batch: 1310 / 1875], loss: 0.984\n",
      "[Epoch: 1, Batch: 1320 / 1875], loss: 0.929\n",
      "[Epoch: 1, Batch: 1330 / 1875], loss: 0.940\n",
      "[Epoch: 1, Batch: 1340 / 1875], loss: 0.942\n",
      "[Epoch: 1, Batch: 1350 / 1875], loss: 0.945\n",
      "[Epoch: 1, Batch: 1360 / 1875], loss: 1.060\n",
      "[Epoch: 1, Batch: 1370 / 1875], loss: 1.056\n",
      "[Epoch: 1, Batch: 1380 / 1875], loss: 0.953\n",
      "[Epoch: 1, Batch: 1390 / 1875], loss: 0.913\n",
      "[Epoch: 1, Batch: 1400 / 1875], loss: 0.894\n",
      "[Epoch: 1, Batch: 1410 / 1875], loss: 0.824\n",
      "[Epoch: 1, Batch: 1420 / 1875], loss: 1.038\n",
      "[Epoch: 1, Batch: 1430 / 1875], loss: 0.931\n",
      "[Epoch: 1, Batch: 1440 / 1875], loss: 1.035\n",
      "[Epoch: 1, Batch: 1450 / 1875], loss: 0.938\n",
      "[Epoch: 1, Batch: 1460 / 1875], loss: 0.933\n",
      "[Epoch: 1, Batch: 1470 / 1875], loss: 0.816\n",
      "[Epoch: 1, Batch: 1480 / 1875], loss: 0.866\n",
      "[Epoch: 1, Batch: 1490 / 1875], loss: 0.938\n",
      "[Epoch: 1, Batch: 1500 / 1875], loss: 0.869\n",
      "[Epoch: 1, Batch: 1510 / 1875], loss: 0.866\n",
      "[Epoch: 1, Batch: 1520 / 1875], loss: 0.829\n",
      "[Epoch: 1, Batch: 1530 / 1875], loss: 0.909\n",
      "[Epoch: 1, Batch: 1540 / 1875], loss: 0.928\n",
      "[Epoch: 1, Batch: 1550 / 1875], loss: 0.921\n",
      "[Epoch: 1, Batch: 1560 / 1875], loss: 0.749\n",
      "[Epoch: 1, Batch: 1570 / 1875], loss: 0.821\n",
      "[Epoch: 1, Batch: 1580 / 1875], loss: 0.882\n",
      "[Epoch: 1, Batch: 1590 / 1875], loss: 0.860\n",
      "[Epoch: 1, Batch: 1600 / 1875], loss: 0.936\n",
      "[Epoch: 1, Batch: 1610 / 1875], loss: 0.920\n",
      "[Epoch: 1, Batch: 1620 / 1875], loss: 0.909\n",
      "[Epoch: 1, Batch: 1630 / 1875], loss: 0.977\n",
      "[Epoch: 1, Batch: 1640 / 1875], loss: 0.914\n",
      "[Epoch: 1, Batch: 1650 / 1875], loss: 0.796\n",
      "[Epoch: 1, Batch: 1660 / 1875], loss: 0.862\n",
      "[Epoch: 1, Batch: 1670 / 1875], loss: 0.864\n",
      "[Epoch: 1, Batch: 1680 / 1875], loss: 0.896\n",
      "[Epoch: 1, Batch: 1690 / 1875], loss: 0.832\n",
      "[Epoch: 1, Batch: 1700 / 1875], loss: 0.894\n",
      "[Epoch: 1, Batch: 1710 / 1875], loss: 0.996\n",
      "[Epoch: 1, Batch: 1720 / 1875], loss: 0.784\n",
      "[Epoch: 1, Batch: 1730 / 1875], loss: 0.812\n",
      "[Epoch: 1, Batch: 1740 / 1875], loss: 0.709\n",
      "[Epoch: 1, Batch: 1750 / 1875], loss: 0.833\n",
      "[Epoch: 1, Batch: 1760 / 1875], loss: 0.778\n",
      "[Epoch: 1, Batch: 1770 / 1875], loss: 0.834\n",
      "[Epoch: 1, Batch: 1780 / 1875], loss: 0.912\n",
      "[Epoch: 1, Batch: 1790 / 1875], loss: 0.764\n",
      "[Epoch: 1, Batch: 1800 / 1875], loss: 0.834\n",
      "[Epoch: 1, Batch: 1810 / 1875], loss: 0.718\n",
      "[Epoch: 1, Batch: 1820 / 1875], loss: 0.792\n",
      "[Epoch: 1, Batch: 1830 / 1875], loss: 0.792\n",
      "[Epoch: 1, Batch: 1840 / 1875], loss: 0.765\n",
      "[Epoch: 1, Batch: 1850 / 1875], loss: 0.799\n",
      "[Epoch: 1, Batch: 1860 / 1875], loss: 0.796\n",
      "[Epoch: 1, Batch: 1870 / 1875], loss: 0.933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid accuracy: 81 %\n",
      "[Epoch: 2, Batch:   10 / 1875], loss: 0.588\n",
      "[Epoch: 2, Batch:   20 / 1875], loss: 0.749\n",
      "[Epoch: 2, Batch:   30 / 1875], loss: 0.745\n",
      "[Epoch: 2, Batch:   40 / 1875], loss: 0.710\n",
      "[Epoch: 2, Batch:   50 / 1875], loss: 0.680\n",
      "[Epoch: 2, Batch:   60 / 1875], loss: 0.717\n",
      "[Epoch: 2, Batch:   70 / 1875], loss: 0.627\n",
      "[Epoch: 2, Batch:   80 / 1875], loss: 0.625\n",
      "[Epoch: 2, Batch:   90 / 1875], loss: 0.644\n",
      "[Epoch: 2, Batch:  100 / 1875], loss: 0.606\n",
      "[Epoch: 2, Batch:  110 / 1875], loss: 0.678\n",
      "[Epoch: 2, Batch:  120 / 1875], loss: 0.616\n",
      "[Epoch: 2, Batch:  130 / 1875], loss: 0.720\n",
      "[Epoch: 2, Batch:  140 / 1875], loss: 0.707\n",
      "[Epoch: 2, Batch:  150 / 1875], loss: 0.779\n",
      "[Epoch: 2, Batch:  160 / 1875], loss: 0.719\n",
      "[Epoch: 2, Batch:  170 / 1875], loss: 0.671\n",
      "[Epoch: 2, Batch:  180 / 1875], loss: 0.714\n",
      "[Epoch: 2, Batch:  190 / 1875], loss: 0.709\n",
      "[Epoch: 2, Batch:  200 / 1875], loss: 0.657\n",
      "[Epoch: 2, Batch:  210 / 1875], loss: 0.712\n",
      "[Epoch: 2, Batch:  220 / 1875], loss: 0.681\n",
      "[Epoch: 2, Batch:  230 / 1875], loss: 0.825\n",
      "[Epoch: 2, Batch:  240 / 1875], loss: 0.791\n",
      "[Epoch: 2, Batch:  250 / 1875], loss: 0.608\n",
      "[Epoch: 2, Batch:  260 / 1875], loss: 0.588\n",
      "[Epoch: 2, Batch:  270 / 1875], loss: 0.624\n",
      "[Epoch: 2, Batch:  280 / 1875], loss: 0.547\n",
      "[Epoch: 2, Batch:  290 / 1875], loss: 0.615\n",
      "[Epoch: 2, Batch:  300 / 1875], loss: 0.648\n",
      "[Epoch: 2, Batch:  310 / 1875], loss: 0.676\n",
      "[Epoch: 2, Batch:  320 / 1875], loss: 0.675\n",
      "[Epoch: 2, Batch:  330 / 1875], loss: 0.691\n",
      "[Epoch: 2, Batch:  340 / 1875], loss: 0.652\n",
      "[Epoch: 2, Batch:  350 / 1875], loss: 0.777\n",
      "[Epoch: 2, Batch:  360 / 1875], loss: 0.658\n",
      "[Epoch: 2, Batch:  370 / 1875], loss: 0.591\n",
      "[Epoch: 2, Batch:  380 / 1875], loss: 0.666\n",
      "[Epoch: 2, Batch:  390 / 1875], loss: 0.501\n",
      "[Epoch: 2, Batch:  400 / 1875], loss: 0.476\n",
      "[Epoch: 2, Batch:  410 / 1875], loss: 0.564\n",
      "[Epoch: 2, Batch:  420 / 1875], loss: 0.668\n",
      "[Epoch: 2, Batch:  430 / 1875], loss: 0.566\n",
      "[Epoch: 2, Batch:  440 / 1875], loss: 0.554\n",
      "[Epoch: 2, Batch:  450 / 1875], loss: 0.522\n",
      "[Epoch: 2, Batch:  460 / 1875], loss: 0.625\n",
      "[Epoch: 2, Batch:  470 / 1875], loss: 0.522\n",
      "[Epoch: 2, Batch:  480 / 1875], loss: 0.490\n",
      "[Epoch: 2, Batch:  490 / 1875], loss: 0.534\n",
      "[Epoch: 2, Batch:  500 / 1875], loss: 0.565\n",
      "[Epoch: 2, Batch:  510 / 1875], loss: 0.533\n",
      "[Epoch: 2, Batch:  520 / 1875], loss: 0.540\n",
      "[Epoch: 2, Batch:  530 / 1875], loss: 0.549\n",
      "[Epoch: 2, Batch:  540 / 1875], loss: 0.564\n",
      "[Epoch: 2, Batch:  550 / 1875], loss: 0.602\n",
      "[Epoch: 2, Batch:  560 / 1875], loss: 0.581\n",
      "[Epoch: 2, Batch:  570 / 1875], loss: 0.628\n",
      "[Epoch: 2, Batch:  580 / 1875], loss: 0.548\n",
      "[Epoch: 2, Batch:  590 / 1875], loss: 0.495\n",
      "[Epoch: 2, Batch:  600 / 1875], loss: 0.490\n",
      "[Epoch: 2, Batch:  610 / 1875], loss: 0.420\n",
      "[Epoch: 2, Batch:  620 / 1875], loss: 0.538\n",
      "[Epoch: 2, Batch:  630 / 1875], loss: 0.447\n",
      "[Epoch: 2, Batch:  640 / 1875], loss: 0.622\n",
      "[Epoch: 2, Batch:  650 / 1875], loss: 0.499\n",
      "[Epoch: 2, Batch:  660 / 1875], loss: 0.502\n",
      "[Epoch: 2, Batch:  670 / 1875], loss: 0.499\n",
      "[Epoch: 2, Batch:  680 / 1875], loss: 0.540\n",
      "[Epoch: 2, Batch:  690 / 1875], loss: 0.462\n",
      "[Epoch: 2, Batch:  700 / 1875], loss: 0.416\n",
      "[Epoch: 2, Batch:  710 / 1875], loss: 0.426\n",
      "[Epoch: 2, Batch:  720 / 1875], loss: 0.397\n",
      "[Epoch: 2, Batch:  730 / 1875], loss: 0.410\n",
      "[Epoch: 2, Batch:  740 / 1875], loss: 0.458\n",
      "[Epoch: 2, Batch:  750 / 1875], loss: 0.541\n",
      "[Epoch: 2, Batch:  760 / 1875], loss: 0.447\n",
      "[Epoch: 2, Batch:  770 / 1875], loss: 0.465\n",
      "[Epoch: 2, Batch:  780 / 1875], loss: 0.468\n",
      "[Epoch: 2, Batch:  790 / 1875], loss: 0.465\n",
      "[Epoch: 2, Batch:  800 / 1875], loss: 0.412\n",
      "[Epoch: 2, Batch:  810 / 1875], loss: 0.515\n",
      "[Epoch: 2, Batch:  820 / 1875], loss: 0.398\n",
      "[Epoch: 2, Batch:  830 / 1875], loss: 0.516\n",
      "[Epoch: 2, Batch:  840 / 1875], loss: 0.511\n",
      "[Epoch: 2, Batch:  850 / 1875], loss: 0.459\n",
      "[Epoch: 2, Batch:  860 / 1875], loss: 0.420\n",
      "[Epoch: 2, Batch:  870 / 1875], loss: 0.467\n",
      "[Epoch: 2, Batch:  880 / 1875], loss: 0.441\n",
      "[Epoch: 2, Batch:  890 / 1875], loss: 0.394\n",
      "[Epoch: 2, Batch:  900 / 1875], loss: 0.372\n",
      "[Epoch: 2, Batch:  910 / 1875], loss: 0.433\n",
      "[Epoch: 2, Batch:  920 / 1875], loss: 0.412\n",
      "[Epoch: 2, Batch:  930 / 1875], loss: 0.417\n",
      "[Epoch: 2, Batch:  940 / 1875], loss: 0.522\n",
      "[Epoch: 2, Batch:  950 / 1875], loss: 0.437\n",
      "[Epoch: 2, Batch:  960 / 1875], loss: 0.421\n",
      "[Epoch: 2, Batch:  970 / 1875], loss: 0.484\n",
      "[Epoch: 2, Batch:  980 / 1875], loss: 0.435\n",
      "[Epoch: 2, Batch:  990 / 1875], loss: 0.462\n",
      "[Epoch: 2, Batch: 1000 / 1875], loss: 0.362\n",
      "[Epoch: 2, Batch: 1010 / 1875], loss: 0.380\n",
      "[Epoch: 2, Batch: 1020 / 1875], loss: 0.395\n",
      "[Epoch: 2, Batch: 1030 / 1875], loss: 0.365\n",
      "[Epoch: 2, Batch: 1040 / 1875], loss: 0.419\n",
      "[Epoch: 2, Batch: 1050 / 1875], loss: 0.401\n",
      "[Epoch: 2, Batch: 1060 / 1875], loss: 0.435\n",
      "[Epoch: 2, Batch: 1070 / 1875], loss: 0.322\n",
      "[Epoch: 2, Batch: 1080 / 1875], loss: 0.364\n",
      "[Epoch: 2, Batch: 1090 / 1875], loss: 0.381\n",
      "[Epoch: 2, Batch: 1100 / 1875], loss: 0.475\n",
      "[Epoch: 2, Batch: 1110 / 1875], loss: 0.308\n",
      "[Epoch: 2, Batch: 1120 / 1875], loss: 0.372\n",
      "[Epoch: 2, Batch: 1130 / 1875], loss: 0.425\n",
      "[Epoch: 2, Batch: 1140 / 1875], loss: 0.319\n",
      "[Epoch: 2, Batch: 1150 / 1875], loss: 0.409\n",
      "[Epoch: 2, Batch: 1160 / 1875], loss: 0.377\n",
      "[Epoch: 2, Batch: 1170 / 1875], loss: 0.450\n",
      "[Epoch: 2, Batch: 1180 / 1875], loss: 0.310\n",
      "[Epoch: 2, Batch: 1190 / 1875], loss: 0.401\n",
      "[Epoch: 2, Batch: 1200 / 1875], loss: 0.373\n",
      "[Epoch: 2, Batch: 1210 / 1875], loss: 0.351\n",
      "[Epoch: 2, Batch: 1220 / 1875], loss: 0.305\n",
      "[Epoch: 2, Batch: 1230 / 1875], loss: 0.405\n",
      "[Epoch: 2, Batch: 1240 / 1875], loss: 0.372\n",
      "[Epoch: 2, Batch: 1250 / 1875], loss: 0.388\n",
      "[Epoch: 2, Batch: 1260 / 1875], loss: 0.376\n",
      "[Epoch: 2, Batch: 1270 / 1875], loss: 0.436\n",
      "[Epoch: 2, Batch: 1280 / 1875], loss: 0.309\n",
      "[Epoch: 2, Batch: 1290 / 1875], loss: 0.371\n",
      "[Epoch: 2, Batch: 1300 / 1875], loss: 0.413\n",
      "[Epoch: 2, Batch: 1310 / 1875], loss: 0.422\n",
      "[Epoch: 2, Batch: 1320 / 1875], loss: 0.395\n",
      "[Epoch: 2, Batch: 1330 / 1875], loss: 0.263\n",
      "[Epoch: 2, Batch: 1340 / 1875], loss: 0.382\n",
      "[Epoch: 2, Batch: 1350 / 1875], loss: 0.361\n",
      "[Epoch: 2, Batch: 1360 / 1875], loss: 0.383\n",
      "[Epoch: 2, Batch: 1370 / 1875], loss: 0.332\n",
      "[Epoch: 2, Batch: 1380 / 1875], loss: 0.337\n",
      "[Epoch: 2, Batch: 1390 / 1875], loss: 0.369\n",
      "[Epoch: 2, Batch: 1400 / 1875], loss: 0.335\n",
      "[Epoch: 2, Batch: 1410 / 1875], loss: 0.340\n",
      "[Epoch: 2, Batch: 1420 / 1875], loss: 0.241\n",
      "[Epoch: 2, Batch: 1430 / 1875], loss: 0.306\n",
      "[Epoch: 2, Batch: 1440 / 1875], loss: 0.264\n",
      "[Epoch: 2, Batch: 1450 / 1875], loss: 0.292\n",
      "[Epoch: 2, Batch: 1460 / 1875], loss: 0.384\n",
      "[Epoch: 2, Batch: 1470 / 1875], loss: 0.304\n",
      "[Epoch: 2, Batch: 1480 / 1875], loss: 0.339\n",
      "[Epoch: 2, Batch: 1490 / 1875], loss: 0.376\n",
      "[Epoch: 2, Batch: 1500 / 1875], loss: 0.340\n",
      "[Epoch: 2, Batch: 1510 / 1875], loss: 0.260\n",
      "[Epoch: 2, Batch: 1520 / 1875], loss: 0.377\n",
      "[Epoch: 2, Batch: 1530 / 1875], loss: 0.342\n",
      "[Epoch: 2, Batch: 1540 / 1875], loss: 0.331\n",
      "[Epoch: 2, Batch: 1550 / 1875], loss: 0.251\n",
      "[Epoch: 2, Batch: 1560 / 1875], loss: 0.336\n",
      "[Epoch: 2, Batch: 1570 / 1875], loss: 0.350\n",
      "[Epoch: 2, Batch: 1580 / 1875], loss: 0.385\n",
      "[Epoch: 2, Batch: 1590 / 1875], loss: 0.334\n",
      "[Epoch: 2, Batch: 1600 / 1875], loss: 0.446\n",
      "[Epoch: 2, Batch: 1610 / 1875], loss: 0.344\n",
      "[Epoch: 2, Batch: 1620 / 1875], loss: 0.350\n",
      "[Epoch: 2, Batch: 1630 / 1875], loss: 0.279\n",
      "[Epoch: 2, Batch: 1640 / 1875], loss: 0.302\n",
      "[Epoch: 2, Batch: 1650 / 1875], loss: 0.336\n",
      "[Epoch: 2, Batch: 1660 / 1875], loss: 0.287\n",
      "[Epoch: 2, Batch: 1670 / 1875], loss: 0.264\n",
      "[Epoch: 2, Batch: 1680 / 1875], loss: 0.310\n",
      "[Epoch: 2, Batch: 1690 / 1875], loss: 0.336\n",
      "[Epoch: 2, Batch: 1700 / 1875], loss: 0.272\n",
      "[Epoch: 2, Batch: 1710 / 1875], loss: 0.255\n",
      "[Epoch: 2, Batch: 1720 / 1875], loss: 0.333\n",
      "[Epoch: 2, Batch: 1730 / 1875], loss: 0.241\n",
      "[Epoch: 2, Batch: 1740 / 1875], loss: 0.299\n",
      "[Epoch: 2, Batch: 1750 / 1875], loss: 0.380\n",
      "[Epoch: 2, Batch: 1760 / 1875], loss: 0.321\n",
      "[Epoch: 2, Batch: 1770 / 1875], loss: 0.413\n",
      "[Epoch: 2, Batch: 1780 / 1875], loss: 0.354\n",
      "[Epoch: 2, Batch: 1790 / 1875], loss: 0.375\n",
      "[Epoch: 2, Batch: 1800 / 1875], loss: 0.273\n",
      "[Epoch: 2, Batch: 1810 / 1875], loss: 0.345\n",
      "[Epoch: 2, Batch: 1820 / 1875], loss: 0.276\n",
      "[Epoch: 2, Batch: 1830 / 1875], loss: 0.318\n",
      "[Epoch: 2, Batch: 1840 / 1875], loss: 0.350\n",
      "[Epoch: 2, Batch: 1850 / 1875], loss: 0.329\n",
      "[Epoch: 2, Batch: 1860 / 1875], loss: 0.330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 2, Batch: 1870 / 1875], loss: 0.341\n",
      "Valid accuracy: 77 %\n",
      "[Epoch: 3, Batch:   10 / 1875], loss: 0.337\n",
      "[Epoch: 3, Batch:   20 / 1875], loss: 0.281\n",
      "[Epoch: 3, Batch:   30 / 1875], loss: 0.317\n",
      "[Epoch: 3, Batch:   40 / 1875], loss: 0.275\n",
      "[Epoch: 3, Batch:   50 / 1875], loss: 0.296\n",
      "[Epoch: 3, Batch:   60 / 1875], loss: 0.239\n",
      "[Epoch: 3, Batch:   70 / 1875], loss: 0.255\n",
      "[Epoch: 3, Batch:   80 / 1875], loss: 0.310\n",
      "[Epoch: 3, Batch:   90 / 1875], loss: 0.305\n",
      "[Epoch: 3, Batch:  100 / 1875], loss: 0.269\n",
      "[Epoch: 3, Batch:  110 / 1875], loss: 0.265\n",
      "[Epoch: 3, Batch:  120 / 1875], loss: 0.278\n",
      "[Epoch: 3, Batch:  130 / 1875], loss: 0.307\n",
      "[Epoch: 3, Batch:  140 / 1875], loss: 0.372\n",
      "[Epoch: 3, Batch:  150 / 1875], loss: 0.281\n",
      "[Epoch: 3, Batch:  160 / 1875], loss: 0.262\n",
      "[Epoch: 3, Batch:  170 / 1875], loss: 0.276\n",
      "[Epoch: 3, Batch:  180 / 1875], loss: 0.281\n",
      "[Epoch: 3, Batch:  190 / 1875], loss: 0.211\n",
      "[Epoch: 3, Batch:  200 / 1875], loss: 0.278\n",
      "[Epoch: 3, Batch:  210 / 1875], loss: 0.302\n",
      "[Epoch: 3, Batch:  220 / 1875], loss: 0.299\n",
      "[Epoch: 3, Batch:  230 / 1875], loss: 0.334\n",
      "[Epoch: 3, Batch:  240 / 1875], loss: 0.321\n",
      "[Epoch: 3, Batch:  250 / 1875], loss: 0.304\n",
      "[Epoch: 3, Batch:  260 / 1875], loss: 0.301\n",
      "[Epoch: 3, Batch:  270 / 1875], loss: 0.277\n",
      "[Epoch: 3, Batch:  280 / 1875], loss: 0.354\n",
      "[Epoch: 3, Batch:  290 / 1875], loss: 0.360\n",
      "[Epoch: 3, Batch:  300 / 1875], loss: 0.333\n",
      "[Epoch: 3, Batch:  310 / 1875], loss: 0.336\n",
      "[Epoch: 3, Batch:  320 / 1875], loss: 0.334\n",
      "[Epoch: 3, Batch:  330 / 1875], loss: 0.297\n",
      "[Epoch: 3, Batch:  340 / 1875], loss: 0.254\n",
      "[Epoch: 3, Batch:  350 / 1875], loss: 0.240\n",
      "[Epoch: 3, Batch:  360 / 1875], loss: 0.381\n",
      "[Epoch: 3, Batch:  370 / 1875], loss: 0.282\n",
      "[Epoch: 3, Batch:  380 / 1875], loss: 0.246\n",
      "[Epoch: 3, Batch:  390 / 1875], loss: 0.243\n",
      "[Epoch: 3, Batch:  400 / 1875], loss: 0.312\n",
      "[Epoch: 3, Batch:  410 / 1875], loss: 0.287\n",
      "[Epoch: 3, Batch:  420 / 1875], loss: 0.261\n",
      "[Epoch: 3, Batch:  430 / 1875], loss: 0.230\n",
      "[Epoch: 3, Batch:  440 / 1875], loss: 0.389\n",
      "[Epoch: 3, Batch:  450 / 1875], loss: 0.409\n",
      "[Epoch: 3, Batch:  460 / 1875], loss: 0.285\n",
      "[Epoch: 3, Batch:  470 / 1875], loss: 0.237\n",
      "[Epoch: 3, Batch:  480 / 1875], loss: 0.424\n",
      "[Epoch: 3, Batch:  490 / 1875], loss: 0.295\n",
      "[Epoch: 3, Batch:  500 / 1875], loss: 0.269\n",
      "[Epoch: 3, Batch:  510 / 1875], loss: 0.234\n",
      "[Epoch: 3, Batch:  520 / 1875], loss: 0.345\n",
      "[Epoch: 3, Batch:  530 / 1875], loss: 0.309\n",
      "[Epoch: 3, Batch:  540 / 1875], loss: 0.328\n",
      "[Epoch: 3, Batch:  550 / 1875], loss: 0.353\n",
      "[Epoch: 3, Batch:  560 / 1875], loss: 0.346\n",
      "[Epoch: 3, Batch:  570 / 1875], loss: 0.313\n",
      "[Epoch: 3, Batch:  580 / 1875], loss: 0.278\n",
      "[Epoch: 3, Batch:  590 / 1875], loss: 0.270\n",
      "[Epoch: 3, Batch:  600 / 1875], loss: 0.315\n",
      "[Epoch: 3, Batch:  610 / 1875], loss: 0.289\n",
      "[Epoch: 3, Batch:  620 / 1875], loss: 0.179\n",
      "[Epoch: 3, Batch:  630 / 1875], loss: 0.274\n",
      "[Epoch: 3, Batch:  640 / 1875], loss: 0.268\n",
      "[Epoch: 3, Batch:  650 / 1875], loss: 0.334\n",
      "[Epoch: 3, Batch:  660 / 1875], loss: 0.255\n",
      "[Epoch: 3, Batch:  670 / 1875], loss: 0.279\n",
      "[Epoch: 3, Batch:  680 / 1875], loss: 0.314\n",
      "[Epoch: 3, Batch:  690 / 1875], loss: 0.332\n",
      "[Epoch: 3, Batch:  700 / 1875], loss: 0.200\n",
      "[Epoch: 3, Batch:  710 / 1875], loss: 0.257\n",
      "[Epoch: 3, Batch:  720 / 1875], loss: 0.312\n",
      "[Epoch: 3, Batch:  730 / 1875], loss: 0.249\n",
      "[Epoch: 3, Batch:  740 / 1875], loss: 0.289\n",
      "[Epoch: 3, Batch:  750 / 1875], loss: 0.240\n",
      "[Epoch: 3, Batch:  760 / 1875], loss: 0.252\n",
      "[Epoch: 3, Batch:  770 / 1875], loss: 0.346\n",
      "[Epoch: 3, Batch:  780 / 1875], loss: 0.324\n",
      "[Epoch: 3, Batch:  790 / 1875], loss: 0.246\n",
      "[Epoch: 3, Batch:  800 / 1875], loss: 0.350\n",
      "[Epoch: 3, Batch:  810 / 1875], loss: 0.266\n",
      "[Epoch: 3, Batch:  820 / 1875], loss: 0.285\n",
      "[Epoch: 3, Batch:  830 / 1875], loss: 0.269\n",
      "[Epoch: 3, Batch:  840 / 1875], loss: 0.259\n",
      "[Epoch: 3, Batch:  850 / 1875], loss: 0.235\n",
      "[Epoch: 3, Batch:  860 / 1875], loss: 0.250\n",
      "[Epoch: 3, Batch:  870 / 1875], loss: 0.195\n",
      "[Epoch: 3, Batch:  880 / 1875], loss: 0.233\n",
      "[Epoch: 3, Batch:  890 / 1875], loss: 0.224\n",
      "[Epoch: 3, Batch:  900 / 1875], loss: 0.223\n",
      "[Epoch: 3, Batch:  910 / 1875], loss: 0.374\n",
      "[Epoch: 3, Batch:  920 / 1875], loss: 0.251\n",
      "[Epoch: 3, Batch:  930 / 1875], loss: 0.234\n",
      "[Epoch: 3, Batch:  940 / 1875], loss: 0.224\n",
      "[Epoch: 3, Batch:  950 / 1875], loss: 0.237\n",
      "[Epoch: 3, Batch:  960 / 1875], loss: 0.247\n",
      "[Epoch: 3, Batch:  970 / 1875], loss: 0.306\n",
      "[Epoch: 3, Batch:  980 / 1875], loss: 0.263\n",
      "[Epoch: 3, Batch:  990 / 1875], loss: 0.279\n",
      "[Epoch: 3, Batch: 1000 / 1875], loss: 0.264\n",
      "[Epoch: 3, Batch: 1010 / 1875], loss: 0.324\n",
      "[Epoch: 3, Batch: 1020 / 1875], loss: 0.319\n",
      "[Epoch: 3, Batch: 1030 / 1875], loss: 0.245\n",
      "[Epoch: 3, Batch: 1040 / 1875], loss: 0.245\n",
      "[Epoch: 3, Batch: 1050 / 1875], loss: 0.242\n",
      "[Epoch: 3, Batch: 1060 / 1875], loss: 0.239\n",
      "[Epoch: 3, Batch: 1070 / 1875], loss: 0.246\n",
      "[Epoch: 3, Batch: 1080 / 1875], loss: 0.253\n",
      "[Epoch: 3, Batch: 1090 / 1875], loss: 0.244\n",
      "[Epoch: 3, Batch: 1100 / 1875], loss: 0.209\n",
      "[Epoch: 3, Batch: 1110 / 1875], loss: 0.266\n",
      "[Epoch: 3, Batch: 1120 / 1875], loss: 0.254\n",
      "[Epoch: 3, Batch: 1130 / 1875], loss: 0.315\n",
      "[Epoch: 3, Batch: 1140 / 1875], loss: 0.268\n",
      "[Epoch: 3, Batch: 1150 / 1875], loss: 0.241\n",
      "[Epoch: 3, Batch: 1160 / 1875], loss: 0.179\n",
      "[Epoch: 3, Batch: 1170 / 1875], loss: 0.223\n",
      "[Epoch: 3, Batch: 1180 / 1875], loss: 0.229\n",
      "[Epoch: 3, Batch: 1190 / 1875], loss: 0.276\n",
      "[Epoch: 3, Batch: 1200 / 1875], loss: 0.204\n",
      "[Epoch: 3, Batch: 1210 / 1875], loss: 0.240\n",
      "[Epoch: 3, Batch: 1220 / 1875], loss: 0.230\n",
      "[Epoch: 3, Batch: 1230 / 1875], loss: 0.235\n",
      "[Epoch: 3, Batch: 1240 / 1875], loss: 0.269\n",
      "[Epoch: 3, Batch: 1250 / 1875], loss: 0.310\n",
      "[Epoch: 3, Batch: 1260 / 1875], loss: 0.294\n",
      "[Epoch: 3, Batch: 1270 / 1875], loss: 0.185\n",
      "[Epoch: 3, Batch: 1280 / 1875], loss: 0.288\n",
      "[Epoch: 3, Batch: 1290 / 1875], loss: 0.255\n",
      "[Epoch: 3, Batch: 1300 / 1875], loss: 0.214\n",
      "[Epoch: 3, Batch: 1310 / 1875], loss: 0.287\n",
      "[Epoch: 3, Batch: 1320 / 1875], loss: 0.287\n",
      "[Epoch: 3, Batch: 1330 / 1875], loss: 0.200\n",
      "[Epoch: 3, Batch: 1340 / 1875], loss: 0.192\n",
      "[Epoch: 3, Batch: 1350 / 1875], loss: 0.216\n",
      "[Epoch: 3, Batch: 1360 / 1875], loss: 0.266\n",
      "[Epoch: 3, Batch: 1370 / 1875], loss: 0.305\n",
      "[Epoch: 3, Batch: 1380 / 1875], loss: 0.290\n",
      "[Epoch: 3, Batch: 1390 / 1875], loss: 0.218\n",
      "[Epoch: 3, Batch: 1400 / 1875], loss: 0.235\n",
      "[Epoch: 3, Batch: 1410 / 1875], loss: 0.290\n",
      "[Epoch: 3, Batch: 1420 / 1875], loss: 0.249\n",
      "[Epoch: 3, Batch: 1430 / 1875], loss: 0.315\n",
      "[Epoch: 3, Batch: 1440 / 1875], loss: 0.266\n",
      "[Epoch: 3, Batch: 1450 / 1875], loss: 0.265\n",
      "[Epoch: 3, Batch: 1460 / 1875], loss: 0.186\n",
      "[Epoch: 3, Batch: 1470 / 1875], loss: 0.233\n",
      "[Epoch: 3, Batch: 1480 / 1875], loss: 0.217\n",
      "[Epoch: 3, Batch: 1490 / 1875], loss: 0.264\n",
      "[Epoch: 3, Batch: 1500 / 1875], loss: 0.157\n",
      "[Epoch: 3, Batch: 1510 / 1875], loss: 0.211\n",
      "[Epoch: 3, Batch: 1520 / 1875], loss: 0.225\n",
      "[Epoch: 3, Batch: 1530 / 1875], loss: 0.242\n",
      "[Epoch: 3, Batch: 1540 / 1875], loss: 0.220\n",
      "[Epoch: 3, Batch: 1550 / 1875], loss: 0.280\n",
      "[Epoch: 3, Batch: 1560 / 1875], loss: 0.236\n",
      "[Epoch: 3, Batch: 1570 / 1875], loss: 0.294\n",
      "[Epoch: 3, Batch: 1580 / 1875], loss: 0.283\n",
      "[Epoch: 3, Batch: 1590 / 1875], loss: 0.275\n",
      "[Epoch: 3, Batch: 1600 / 1875], loss: 0.224\n",
      "[Epoch: 3, Batch: 1610 / 1875], loss: 0.195\n",
      "[Epoch: 3, Batch: 1620 / 1875], loss: 0.197\n",
      "[Epoch: 3, Batch: 1630 / 1875], loss: 0.212\n",
      "[Epoch: 3, Batch: 1640 / 1875], loss: 0.237\n",
      "[Epoch: 3, Batch: 1650 / 1875], loss: 0.247\n",
      "[Epoch: 3, Batch: 1660 / 1875], loss: 0.263\n",
      "[Epoch: 3, Batch: 1670 / 1875], loss: 0.301\n",
      "[Epoch: 3, Batch: 1680 / 1875], loss: 0.208\n",
      "[Epoch: 3, Batch: 1690 / 1875], loss: 0.308\n",
      "[Epoch: 3, Batch: 1700 / 1875], loss: 0.256\n",
      "[Epoch: 3, Batch: 1710 / 1875], loss: 0.232\n",
      "[Epoch: 3, Batch: 1720 / 1875], loss: 0.301\n",
      "[Epoch: 3, Batch: 1730 / 1875], loss: 0.291\n",
      "[Epoch: 3, Batch: 1740 / 1875], loss: 0.229\n",
      "[Epoch: 3, Batch: 1750 / 1875], loss: 0.225\n",
      "[Epoch: 3, Batch: 1760 / 1875], loss: 0.307\n",
      "[Epoch: 3, Batch: 1770 / 1875], loss: 0.243\n",
      "[Epoch: 3, Batch: 1780 / 1875], loss: 0.281\n",
      "[Epoch: 3, Batch: 1790 / 1875], loss: 0.295\n",
      "[Epoch: 3, Batch: 1800 / 1875], loss: 0.158\n",
      "[Epoch: 3, Batch: 1810 / 1875], loss: 0.299\n",
      "[Epoch: 3, Batch: 1820 / 1875], loss: 0.328\n",
      "[Epoch: 3, Batch: 1830 / 1875], loss: 0.255\n",
      "[Epoch: 3, Batch: 1840 / 1875], loss: 0.302\n",
      "[Epoch: 3, Batch: 1850 / 1875], loss: 0.266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 3, Batch: 1860 / 1875], loss: 0.190\n",
      "[Epoch: 3, Batch: 1870 / 1875], loss: 0.180\n",
      "Valid accuracy: 91 %\n",
      "[Epoch: 4, Batch:   10 / 1875], loss: 0.182\n",
      "[Epoch: 4, Batch:   20 / 1875], loss: 0.215\n",
      "[Epoch: 4, Batch:   30 / 1875], loss: 0.188\n",
      "[Epoch: 4, Batch:   40 / 1875], loss: 0.228\n",
      "[Epoch: 4, Batch:   50 / 1875], loss: 0.239\n",
      "[Epoch: 4, Batch:   60 / 1875], loss: 0.182\n",
      "[Epoch: 4, Batch:   70 / 1875], loss: 0.225\n",
      "[Epoch: 4, Batch:   80 / 1875], loss: 0.232\n",
      "[Epoch: 4, Batch:   90 / 1875], loss: 0.231\n",
      "[Epoch: 4, Batch:  100 / 1875], loss: 0.223\n",
      "[Epoch: 4, Batch:  110 / 1875], loss: 0.205\n",
      "[Epoch: 4, Batch:  120 / 1875], loss: 0.240\n",
      "[Epoch: 4, Batch:  130 / 1875], loss: 0.119\n",
      "[Epoch: 4, Batch:  140 / 1875], loss: 0.188\n",
      "[Epoch: 4, Batch:  150 / 1875], loss: 0.204\n",
      "[Epoch: 4, Batch:  160 / 1875], loss: 0.238\n",
      "[Epoch: 4, Batch:  170 / 1875], loss: 0.262\n",
      "[Epoch: 4, Batch:  180 / 1875], loss: 0.250\n",
      "[Epoch: 4, Batch:  190 / 1875], loss: 0.226\n",
      "[Epoch: 4, Batch:  200 / 1875], loss: 0.212\n",
      "[Epoch: 4, Batch:  210 / 1875], loss: 0.276\n",
      "[Epoch: 4, Batch:  220 / 1875], loss: 0.206\n",
      "[Epoch: 4, Batch:  230 / 1875], loss: 0.232\n",
      "[Epoch: 4, Batch:  240 / 1875], loss: 0.277\n",
      "[Epoch: 4, Batch:  250 / 1875], loss: 0.241\n",
      "[Epoch: 4, Batch:  260 / 1875], loss: 0.200\n",
      "[Epoch: 4, Batch:  270 / 1875], loss: 0.145\n",
      "[Epoch: 4, Batch:  280 / 1875], loss: 0.237\n",
      "[Epoch: 4, Batch:  290 / 1875], loss: 0.210\n",
      "[Epoch: 4, Batch:  300 / 1875], loss: 0.237\n",
      "[Epoch: 4, Batch:  310 / 1875], loss: 0.241\n",
      "[Epoch: 4, Batch:  320 / 1875], loss: 0.175\n",
      "[Epoch: 4, Batch:  330 / 1875], loss: 0.156\n",
      "[Epoch: 4, Batch:  340 / 1875], loss: 0.234\n",
      "[Epoch: 4, Batch:  350 / 1875], loss: 0.235\n",
      "[Epoch: 4, Batch:  360 / 1875], loss: 0.208\n",
      "[Epoch: 4, Batch:  370 / 1875], loss: 0.247\n",
      "[Epoch: 4, Batch:  380 / 1875], loss: 0.200\n",
      "[Epoch: 4, Batch:  390 / 1875], loss: 0.168\n",
      "[Epoch: 4, Batch:  400 / 1875], loss: 0.211\n",
      "[Epoch: 4, Batch:  410 / 1875], loss: 0.199\n",
      "[Epoch: 4, Batch:  420 / 1875], loss: 0.252\n",
      "[Epoch: 4, Batch:  430 / 1875], loss: 0.313\n",
      "[Epoch: 4, Batch:  440 / 1875], loss: 0.223\n",
      "[Epoch: 4, Batch:  450 / 1875], loss: 0.253\n",
      "[Epoch: 4, Batch:  460 / 1875], loss: 0.270\n",
      "[Epoch: 4, Batch:  470 / 1875], loss: 0.279\n",
      "[Epoch: 4, Batch:  480 / 1875], loss: 0.346\n",
      "[Epoch: 4, Batch:  490 / 1875], loss: 0.256\n",
      "[Epoch: 4, Batch:  500 / 1875], loss: 0.223\n",
      "[Epoch: 4, Batch:  510 / 1875], loss: 0.233\n",
      "[Epoch: 4, Batch:  520 / 1875], loss: 0.262\n",
      "[Epoch: 4, Batch:  530 / 1875], loss: 0.262\n",
      "[Epoch: 4, Batch:  540 / 1875], loss: 0.325\n",
      "[Epoch: 4, Batch:  550 / 1875], loss: 0.227\n",
      "[Epoch: 4, Batch:  560 / 1875], loss: 0.305\n",
      "[Epoch: 4, Batch:  570 / 1875], loss: 0.257\n",
      "[Epoch: 4, Batch:  580 / 1875], loss: 0.225\n",
      "[Epoch: 4, Batch:  590 / 1875], loss: 0.175\n",
      "[Epoch: 4, Batch:  600 / 1875], loss: 0.215\n",
      "[Epoch: 4, Batch:  610 / 1875], loss: 0.175\n",
      "[Epoch: 4, Batch:  620 / 1875], loss: 0.312\n",
      "[Epoch: 4, Batch:  630 / 1875], loss: 0.214\n",
      "[Epoch: 4, Batch:  640 / 1875], loss: 0.223\n",
      "[Epoch: 4, Batch:  650 / 1875], loss: 0.213\n",
      "[Epoch: 4, Batch:  660 / 1875], loss: 0.258\n",
      "[Epoch: 4, Batch:  670 / 1875], loss: 0.242\n",
      "[Epoch: 4, Batch:  680 / 1875], loss: 0.212\n",
      "[Epoch: 4, Batch:  690 / 1875], loss: 0.204\n",
      "[Epoch: 4, Batch:  700 / 1875], loss: 0.120\n",
      "[Epoch: 4, Batch:  710 / 1875], loss: 0.170\n",
      "[Epoch: 4, Batch:  720 / 1875], loss: 0.268\n",
      "[Epoch: 4, Batch:  730 / 1875], loss: 0.171\n",
      "[Epoch: 4, Batch:  740 / 1875], loss: 0.202\n",
      "[Epoch: 4, Batch:  750 / 1875], loss: 0.232\n",
      "[Epoch: 4, Batch:  760 / 1875], loss: 0.305\n",
      "[Epoch: 4, Batch:  770 / 1875], loss: 0.168\n",
      "[Epoch: 4, Batch:  780 / 1875], loss: 0.157\n",
      "[Epoch: 4, Batch:  790 / 1875], loss: 0.217\n",
      "[Epoch: 4, Batch:  800 / 1875], loss: 0.200\n",
      "[Epoch: 4, Batch:  810 / 1875], loss: 0.222\n",
      "[Epoch: 4, Batch:  820 / 1875], loss: 0.240\n",
      "[Epoch: 4, Batch:  830 / 1875], loss: 0.275\n",
      "[Epoch: 4, Batch:  840 / 1875], loss: 0.223\n",
      "[Epoch: 4, Batch:  850 / 1875], loss: 0.222\n",
      "[Epoch: 4, Batch:  860 / 1875], loss: 0.173\n",
      "[Epoch: 4, Batch:  870 / 1875], loss: 0.225\n",
      "[Epoch: 4, Batch:  880 / 1875], loss: 0.190\n",
      "[Epoch: 4, Batch:  890 / 1875], loss: 0.213\n",
      "[Epoch: 4, Batch:  900 / 1875], loss: 0.242\n",
      "[Epoch: 4, Batch:  910 / 1875], loss: 0.164\n",
      "[Epoch: 4, Batch:  920 / 1875], loss: 0.248\n",
      "[Epoch: 4, Batch:  930 / 1875], loss: 0.227\n",
      "[Epoch: 4, Batch:  940 / 1875], loss: 0.187\n",
      "[Epoch: 4, Batch:  950 / 1875], loss: 0.257\n",
      "[Epoch: 4, Batch:  960 / 1875], loss: 0.214\n",
      "[Epoch: 4, Batch:  970 / 1875], loss: 0.258\n",
      "[Epoch: 4, Batch:  980 / 1875], loss: 0.180\n",
      "[Epoch: 4, Batch:  990 / 1875], loss: 0.196\n",
      "[Epoch: 4, Batch: 1000 / 1875], loss: 0.174\n",
      "[Epoch: 4, Batch: 1010 / 1875], loss: 0.170\n",
      "[Epoch: 4, Batch: 1020 / 1875], loss: 0.258\n",
      "[Epoch: 4, Batch: 1030 / 1875], loss: 0.225\n",
      "[Epoch: 4, Batch: 1040 / 1875], loss: 0.193\n",
      "[Epoch: 4, Batch: 1050 / 1875], loss: 0.232\n",
      "[Epoch: 4, Batch: 1060 / 1875], loss: 0.240\n",
      "[Epoch: 4, Batch: 1070 / 1875], loss: 0.380\n",
      "[Epoch: 4, Batch: 1080 / 1875], loss: 0.174\n",
      "[Epoch: 4, Batch: 1090 / 1875], loss: 0.177\n",
      "[Epoch: 4, Batch: 1100 / 1875], loss: 0.247\n",
      "[Epoch: 4, Batch: 1110 / 1875], loss: 0.219\n",
      "[Epoch: 4, Batch: 1120 / 1875], loss: 0.264\n",
      "[Epoch: 4, Batch: 1130 / 1875], loss: 0.214\n",
      "[Epoch: 4, Batch: 1140 / 1875], loss: 0.324\n",
      "[Epoch: 4, Batch: 1150 / 1875], loss: 0.225\n",
      "[Epoch: 4, Batch: 1160 / 1875], loss: 0.185\n",
      "[Epoch: 4, Batch: 1170 / 1875], loss: 0.200\n",
      "[Epoch: 4, Batch: 1180 / 1875], loss: 0.175\n",
      "[Epoch: 4, Batch: 1190 / 1875], loss: 0.252\n",
      "[Epoch: 4, Batch: 1200 / 1875], loss: 0.239\n",
      "[Epoch: 4, Batch: 1210 / 1875], loss: 0.202\n",
      "[Epoch: 4, Batch: 1220 / 1875], loss: 0.206\n",
      "[Epoch: 4, Batch: 1230 / 1875], loss: 0.132\n",
      "[Epoch: 4, Batch: 1240 / 1875], loss: 0.232\n",
      "[Epoch: 4, Batch: 1250 / 1875], loss: 0.211\n",
      "[Epoch: 4, Batch: 1260 / 1875], loss: 0.235\n",
      "[Epoch: 4, Batch: 1270 / 1875], loss: 0.207\n",
      "[Epoch: 4, Batch: 1280 / 1875], loss: 0.152\n",
      "[Epoch: 4, Batch: 1290 / 1875], loss: 0.206\n",
      "[Epoch: 4, Batch: 1300 / 1875], loss: 0.210\n",
      "[Epoch: 4, Batch: 1310 / 1875], loss: 0.219\n",
      "[Epoch: 4, Batch: 1320 / 1875], loss: 0.331\n",
      "[Epoch: 4, Batch: 1330 / 1875], loss: 0.217\n",
      "[Epoch: 4, Batch: 1340 / 1875], loss: 0.263\n",
      "[Epoch: 4, Batch: 1350 / 1875], loss: 0.118\n",
      "[Epoch: 4, Batch: 1360 / 1875], loss: 0.109\n",
      "[Epoch: 4, Batch: 1370 / 1875], loss: 0.160\n",
      "[Epoch: 4, Batch: 1380 / 1875], loss: 0.194\n",
      "[Epoch: 4, Batch: 1390 / 1875], loss: 0.195\n",
      "[Epoch: 4, Batch: 1400 / 1875], loss: 0.191\n",
      "[Epoch: 4, Batch: 1410 / 1875], loss: 0.223\n",
      "[Epoch: 4, Batch: 1420 / 1875], loss: 0.150\n",
      "[Epoch: 4, Batch: 1430 / 1875], loss: 0.187\n",
      "[Epoch: 4, Batch: 1440 / 1875], loss: 0.172\n",
      "[Epoch: 4, Batch: 1450 / 1875], loss: 0.170\n",
      "[Epoch: 4, Batch: 1460 / 1875], loss: 0.183\n",
      "[Epoch: 4, Batch: 1470 / 1875], loss: 0.183\n",
      "[Epoch: 4, Batch: 1480 / 1875], loss: 0.169\n",
      "[Epoch: 4, Batch: 1490 / 1875], loss: 0.174\n",
      "[Epoch: 4, Batch: 1500 / 1875], loss: 0.233\n",
      "[Epoch: 4, Batch: 1510 / 1875], loss: 0.211\n",
      "[Epoch: 4, Batch: 1520 / 1875], loss: 0.182\n",
      "[Epoch: 4, Batch: 1530 / 1875], loss: 0.240\n",
      "[Epoch: 4, Batch: 1540 / 1875], loss: 0.211\n",
      "[Epoch: 4, Batch: 1550 / 1875], loss: 0.197\n",
      "[Epoch: 4, Batch: 1560 / 1875], loss: 0.186\n",
      "[Epoch: 4, Batch: 1570 / 1875], loss: 0.274\n",
      "[Epoch: 4, Batch: 1580 / 1875], loss: 0.168\n",
      "[Epoch: 4, Batch: 1590 / 1875], loss: 0.248\n",
      "[Epoch: 4, Batch: 1600 / 1875], loss: 0.224\n",
      "[Epoch: 4, Batch: 1610 / 1875], loss: 0.206\n",
      "[Epoch: 4, Batch: 1620 / 1875], loss: 0.207\n",
      "[Epoch: 4, Batch: 1630 / 1875], loss: 0.212\n",
      "[Epoch: 4, Batch: 1640 / 1875], loss: 0.247\n",
      "[Epoch: 4, Batch: 1650 / 1875], loss: 0.221\n",
      "[Epoch: 4, Batch: 1660 / 1875], loss: 0.170\n",
      "[Epoch: 4, Batch: 1670 / 1875], loss: 0.160\n",
      "[Epoch: 4, Batch: 1680 / 1875], loss: 0.161\n",
      "[Epoch: 4, Batch: 1690 / 1875], loss: 0.161\n",
      "[Epoch: 4, Batch: 1700 / 1875], loss: 0.154\n",
      "[Epoch: 4, Batch: 1710 / 1875], loss: 0.194\n",
      "[Epoch: 4, Batch: 1720 / 1875], loss: 0.252\n",
      "[Epoch: 4, Batch: 1730 / 1875], loss: 0.172\n",
      "[Epoch: 4, Batch: 1740 / 1875], loss: 0.177\n",
      "[Epoch: 4, Batch: 1750 / 1875], loss: 0.200\n",
      "[Epoch: 4, Batch: 1760 / 1875], loss: 0.248\n",
      "[Epoch: 4, Batch: 1770 / 1875], loss: 0.233\n",
      "[Epoch: 4, Batch: 1780 / 1875], loss: 0.180\n",
      "[Epoch: 4, Batch: 1790 / 1875], loss: 0.189\n",
      "[Epoch: 4, Batch: 1800 / 1875], loss: 0.249\n",
      "[Epoch: 4, Batch: 1810 / 1875], loss: 0.262\n",
      "[Epoch: 4, Batch: 1820 / 1875], loss: 0.198\n",
      "[Epoch: 4, Batch: 1830 / 1875], loss: 0.233\n",
      "[Epoch: 4, Batch: 1840 / 1875], loss: 0.173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 4, Batch: 1850 / 1875], loss: 0.194\n",
      "[Epoch: 4, Batch: 1860 / 1875], loss: 0.140\n",
      "[Epoch: 4, Batch: 1870 / 1875], loss: 0.229\n",
      "Valid accuracy: 95 %\n",
      "[Epoch: 5, Batch:   10 / 1875], loss: 0.206\n",
      "[Epoch: 5, Batch:   20 / 1875], loss: 0.278\n",
      "[Epoch: 5, Batch:   30 / 1875], loss: 0.173\n",
      "[Epoch: 5, Batch:   40 / 1875], loss: 0.225\n",
      "[Epoch: 5, Batch:   50 / 1875], loss: 0.190\n",
      "[Epoch: 5, Batch:   60 / 1875], loss: 0.222\n",
      "[Epoch: 5, Batch:   70 / 1875], loss: 0.208\n",
      "[Epoch: 5, Batch:   80 / 1875], loss: 0.161\n",
      "[Epoch: 5, Batch:   90 / 1875], loss: 0.168\n",
      "[Epoch: 5, Batch:  100 / 1875], loss: 0.211\n",
      "[Epoch: 5, Batch:  110 / 1875], loss: 0.297\n",
      "[Epoch: 5, Batch:  120 / 1875], loss: 0.246\n",
      "[Epoch: 5, Batch:  130 / 1875], loss: 0.181\n",
      "[Epoch: 5, Batch:  140 / 1875], loss: 0.221\n",
      "[Epoch: 5, Batch:  150 / 1875], loss: 0.167\n",
      "[Epoch: 5, Batch:  160 / 1875], loss: 0.250\n",
      "[Epoch: 5, Batch:  170 / 1875], loss: 0.157\n",
      "[Epoch: 5, Batch:  180 / 1875], loss: 0.161\n",
      "[Epoch: 5, Batch:  190 / 1875], loss: 0.194\n",
      "[Epoch: 5, Batch:  200 / 1875], loss: 0.164\n",
      "[Epoch: 5, Batch:  210 / 1875], loss: 0.236\n",
      "[Epoch: 5, Batch:  220 / 1875], loss: 0.174\n",
      "[Epoch: 5, Batch:  230 / 1875], loss: 0.230\n",
      "[Epoch: 5, Batch:  240 / 1875], loss: 0.175\n",
      "[Epoch: 5, Batch:  250 / 1875], loss: 0.167\n",
      "[Epoch: 5, Batch:  260 / 1875], loss: 0.193\n",
      "[Epoch: 5, Batch:  270 / 1875], loss: 0.203\n",
      "[Epoch: 5, Batch:  280 / 1875], loss: 0.151\n",
      "[Epoch: 5, Batch:  290 / 1875], loss: 0.184\n",
      "[Epoch: 5, Batch:  300 / 1875], loss: 0.207\n",
      "[Epoch: 5, Batch:  310 / 1875], loss: 0.237\n",
      "[Epoch: 5, Batch:  320 / 1875], loss: 0.181\n",
      "[Epoch: 5, Batch:  330 / 1875], loss: 0.148\n",
      "[Epoch: 5, Batch:  340 / 1875], loss: 0.217\n",
      "[Epoch: 5, Batch:  350 / 1875], loss: 0.151\n",
      "[Epoch: 5, Batch:  360 / 1875], loss: 0.230\n",
      "[Epoch: 5, Batch:  370 / 1875], loss: 0.195\n",
      "[Epoch: 5, Batch:  380 / 1875], loss: 0.237\n",
      "[Epoch: 5, Batch:  390 / 1875], loss: 0.217\n",
      "[Epoch: 5, Batch:  400 / 1875], loss: 0.247\n",
      "[Epoch: 5, Batch:  410 / 1875], loss: 0.144\n",
      "[Epoch: 5, Batch:  420 / 1875], loss: 0.176\n",
      "[Epoch: 5, Batch:  430 / 1875], loss: 0.231\n",
      "[Epoch: 5, Batch:  440 / 1875], loss: 0.214\n",
      "[Epoch: 5, Batch:  450 / 1875], loss: 0.214\n",
      "[Epoch: 5, Batch:  460 / 1875], loss: 0.199\n",
      "[Epoch: 5, Batch:  470 / 1875], loss: 0.202\n",
      "[Epoch: 5, Batch:  480 / 1875], loss: 0.159\n",
      "[Epoch: 5, Batch:  490 / 1875], loss: 0.164\n",
      "[Epoch: 5, Batch:  500 / 1875], loss: 0.202\n",
      "[Epoch: 5, Batch:  510 / 1875], loss: 0.223\n",
      "[Epoch: 5, Batch:  520 / 1875], loss: 0.199\n",
      "[Epoch: 5, Batch:  530 / 1875], loss: 0.246\n",
      "[Epoch: 5, Batch:  540 / 1875], loss: 0.195\n",
      "[Epoch: 5, Batch:  550 / 1875], loss: 0.221\n",
      "[Epoch: 5, Batch:  560 / 1875], loss: 0.185\n",
      "[Epoch: 5, Batch:  570 / 1875], loss: 0.164\n",
      "[Epoch: 5, Batch:  580 / 1875], loss: 0.206\n",
      "[Epoch: 5, Batch:  590 / 1875], loss: 0.239\n",
      "[Epoch: 5, Batch:  600 / 1875], loss: 0.139\n",
      "[Epoch: 5, Batch:  610 / 1875], loss: 0.175\n",
      "[Epoch: 5, Batch:  620 / 1875], loss: 0.155\n",
      "[Epoch: 5, Batch:  630 / 1875], loss: 0.243\n",
      "[Epoch: 5, Batch:  640 / 1875], loss: 0.154\n",
      "[Epoch: 5, Batch:  650 / 1875], loss: 0.178\n",
      "[Epoch: 5, Batch:  660 / 1875], loss: 0.263\n",
      "[Epoch: 5, Batch:  670 / 1875], loss: 0.216\n",
      "[Epoch: 5, Batch:  680 / 1875], loss: 0.186\n",
      "[Epoch: 5, Batch:  690 / 1875], loss: 0.224\n",
      "[Epoch: 5, Batch:  700 / 1875], loss: 0.196\n",
      "[Epoch: 5, Batch:  710 / 1875], loss: 0.148\n",
      "[Epoch: 5, Batch:  720 / 1875], loss: 0.219\n",
      "[Epoch: 5, Batch:  730 / 1875], loss: 0.217\n",
      "[Epoch: 5, Batch:  740 / 1875], loss: 0.142\n",
      "[Epoch: 5, Batch:  750 / 1875], loss: 0.160\n",
      "[Epoch: 5, Batch:  760 / 1875], loss: 0.198\n",
      "[Epoch: 5, Batch:  770 / 1875], loss: 0.193\n",
      "[Epoch: 5, Batch:  780 / 1875], loss: 0.169\n",
      "[Epoch: 5, Batch:  790 / 1875], loss: 0.210\n",
      "[Epoch: 5, Batch:  800 / 1875], loss: 0.244\n",
      "[Epoch: 5, Batch:  810 / 1875], loss: 0.145\n",
      "[Epoch: 5, Batch:  820 / 1875], loss: 0.244\n",
      "[Epoch: 5, Batch:  830 / 1875], loss: 0.149\n",
      "[Epoch: 5, Batch:  840 / 1875], loss: 0.186\n",
      "[Epoch: 5, Batch:  850 / 1875], loss: 0.191\n",
      "[Epoch: 5, Batch:  860 / 1875], loss: 0.136\n",
      "[Epoch: 5, Batch:  870 / 1875], loss: 0.142\n",
      "[Epoch: 5, Batch:  880 / 1875], loss: 0.177\n",
      "[Epoch: 5, Batch:  890 / 1875], loss: 0.171\n",
      "[Epoch: 5, Batch:  900 / 1875], loss: 0.157\n",
      "[Epoch: 5, Batch:  910 / 1875], loss: 0.122\n",
      "[Epoch: 5, Batch:  920 / 1875], loss: 0.105\n",
      "[Epoch: 5, Batch:  930 / 1875], loss: 0.137\n",
      "[Epoch: 5, Batch:  940 / 1875], loss: 0.157\n",
      "[Epoch: 5, Batch:  950 / 1875], loss: 0.239\n",
      "[Epoch: 5, Batch:  960 / 1875], loss: 0.216\n",
      "[Epoch: 5, Batch:  970 / 1875], loss: 0.230\n",
      "[Epoch: 5, Batch:  980 / 1875], loss: 0.166\n",
      "[Epoch: 5, Batch:  990 / 1875], loss: 0.202\n",
      "[Epoch: 5, Batch: 1000 / 1875], loss: 0.188\n",
      "[Epoch: 5, Batch: 1010 / 1875], loss: 0.198\n",
      "[Epoch: 5, Batch: 1020 / 1875], loss: 0.225\n",
      "[Epoch: 5, Batch: 1030 / 1875], loss: 0.169\n",
      "[Epoch: 5, Batch: 1040 / 1875], loss: 0.228\n",
      "[Epoch: 5, Batch: 1050 / 1875], loss: 0.215\n",
      "[Epoch: 5, Batch: 1060 / 1875], loss: 0.244\n",
      "[Epoch: 5, Batch: 1070 / 1875], loss: 0.191\n",
      "[Epoch: 5, Batch: 1080 / 1875], loss: 0.282\n",
      "[Epoch: 5, Batch: 1090 / 1875], loss: 0.241\n",
      "[Epoch: 5, Batch: 1100 / 1875], loss: 0.129\n",
      "[Epoch: 5, Batch: 1110 / 1875], loss: 0.215\n",
      "[Epoch: 5, Batch: 1120 / 1875], loss: 0.178\n",
      "[Epoch: 5, Batch: 1130 / 1875], loss: 0.168\n",
      "[Epoch: 5, Batch: 1140 / 1875], loss: 0.162\n",
      "[Epoch: 5, Batch: 1150 / 1875], loss: 0.186\n",
      "[Epoch: 5, Batch: 1160 / 1875], loss: 0.231\n",
      "[Epoch: 5, Batch: 1170 / 1875], loss: 0.126\n",
      "[Epoch: 5, Batch: 1180 / 1875], loss: 0.154\n",
      "[Epoch: 5, Batch: 1190 / 1875], loss: 0.230\n",
      "[Epoch: 5, Batch: 1200 / 1875], loss: 0.239\n",
      "[Epoch: 5, Batch: 1210 / 1875], loss: 0.122\n",
      "[Epoch: 5, Batch: 1220 / 1875], loss: 0.187\n",
      "[Epoch: 5, Batch: 1230 / 1875], loss: 0.171\n",
      "[Epoch: 5, Batch: 1240 / 1875], loss: 0.207\n",
      "[Epoch: 5, Batch: 1250 / 1875], loss: 0.244\n",
      "[Epoch: 5, Batch: 1260 / 1875], loss: 0.096\n",
      "[Epoch: 5, Batch: 1270 / 1875], loss: 0.147\n",
      "[Epoch: 5, Batch: 1280 / 1875], loss: 0.136\n",
      "[Epoch: 5, Batch: 1290 / 1875], loss: 0.131\n",
      "[Epoch: 5, Batch: 1300 / 1875], loss: 0.172\n",
      "[Epoch: 5, Batch: 1310 / 1875], loss: 0.224\n",
      "[Epoch: 5, Batch: 1320 / 1875], loss: 0.123\n",
      "[Epoch: 5, Batch: 1330 / 1875], loss: 0.197\n",
      "[Epoch: 5, Batch: 1340 / 1875], loss: 0.162\n",
      "[Epoch: 5, Batch: 1350 / 1875], loss: 0.149\n",
      "[Epoch: 5, Batch: 1360 / 1875], loss: 0.130\n",
      "[Epoch: 5, Batch: 1370 / 1875], loss: 0.187\n",
      "[Epoch: 5, Batch: 1380 / 1875], loss: 0.250\n",
      "[Epoch: 5, Batch: 1390 / 1875], loss: 0.130\n",
      "[Epoch: 5, Batch: 1400 / 1875], loss: 0.178\n",
      "[Epoch: 5, Batch: 1410 / 1875], loss: 0.157\n",
      "[Epoch: 5, Batch: 1420 / 1875], loss: 0.166\n",
      "[Epoch: 5, Batch: 1430 / 1875], loss: 0.153\n",
      "[Epoch: 5, Batch: 1440 / 1875], loss: 0.217\n",
      "[Epoch: 5, Batch: 1450 / 1875], loss: 0.224\n",
      "[Epoch: 5, Batch: 1460 / 1875], loss: 0.175\n",
      "[Epoch: 5, Batch: 1470 / 1875], loss: 0.155\n",
      "[Epoch: 5, Batch: 1480 / 1875], loss: 0.135\n",
      "[Epoch: 5, Batch: 1490 / 1875], loss: 0.140\n",
      "[Epoch: 5, Batch: 1500 / 1875], loss: 0.138\n",
      "[Epoch: 5, Batch: 1510 / 1875], loss: 0.179\n",
      "[Epoch: 5, Batch: 1520 / 1875], loss: 0.198\n",
      "[Epoch: 5, Batch: 1530 / 1875], loss: 0.218\n",
      "[Epoch: 5, Batch: 1540 / 1875], loss: 0.200\n",
      "[Epoch: 5, Batch: 1550 / 1875], loss: 0.183\n",
      "[Epoch: 5, Batch: 1560 / 1875], loss: 0.198\n",
      "[Epoch: 5, Batch: 1570 / 1875], loss: 0.094\n",
      "[Epoch: 5, Batch: 1580 / 1875], loss: 0.174\n",
      "[Epoch: 5, Batch: 1590 / 1875], loss: 0.117\n",
      "[Epoch: 5, Batch: 1600 / 1875], loss: 0.218\n",
      "[Epoch: 5, Batch: 1610 / 1875], loss: 0.170\n",
      "[Epoch: 5, Batch: 1620 / 1875], loss: 0.239\n",
      "[Epoch: 5, Batch: 1630 / 1875], loss: 0.172\n",
      "[Epoch: 5, Batch: 1640 / 1875], loss: 0.121\n",
      "[Epoch: 5, Batch: 1650 / 1875], loss: 0.176\n",
      "[Epoch: 5, Batch: 1660 / 1875], loss: 0.189\n",
      "[Epoch: 5, Batch: 1670 / 1875], loss: 0.181\n",
      "[Epoch: 5, Batch: 1680 / 1875], loss: 0.243\n",
      "[Epoch: 5, Batch: 1690 / 1875], loss: 0.190\n",
      "[Epoch: 5, Batch: 1700 / 1875], loss: 0.178\n",
      "[Epoch: 5, Batch: 1710 / 1875], loss: 0.198\n",
      "[Epoch: 5, Batch: 1720 / 1875], loss: 0.203\n",
      "[Epoch: 5, Batch: 1730 / 1875], loss: 0.133\n",
      "[Epoch: 5, Batch: 1740 / 1875], loss: 0.249\n",
      "[Epoch: 5, Batch: 1750 / 1875], loss: 0.186\n",
      "[Epoch: 5, Batch: 1760 / 1875], loss: 0.230\n",
      "[Epoch: 5, Batch: 1770 / 1875], loss: 0.220\n",
      "[Epoch: 5, Batch: 1780 / 1875], loss: 0.170\n",
      "[Epoch: 5, Batch: 1790 / 1875], loss: 0.224\n",
      "[Epoch: 5, Batch: 1800 / 1875], loss: 0.184\n",
      "[Epoch: 5, Batch: 1810 / 1875], loss: 0.155\n",
      "[Epoch: 5, Batch: 1820 / 1875], loss: 0.161\n",
      "[Epoch: 5, Batch: 1830 / 1875], loss: 0.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 5, Batch: 1840 / 1875], loss: 0.129\n",
      "[Epoch: 5, Batch: 1850 / 1875], loss: 0.210\n",
      "[Epoch: 5, Batch: 1860 / 1875], loss: 0.187\n",
      "[Epoch: 5, Batch: 1870 / 1875], loss: 0.177\n",
      "Valid accuracy: 90 %\n"
     ]
    }
   ],
   "source": [
    "train(pointnet, train_loader, valid_loader,  save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [   1 /  157]\n",
      "Batch [   2 /  157]\n",
      "Batch [   3 /  157]\n",
      "Batch [   4 /  157]\n",
      "Batch [   5 /  157]\n",
      "Batch [   6 /  157]\n",
      "Batch [   7 /  157]\n",
      "Batch [   8 /  157]\n",
      "Batch [   9 /  157]\n",
      "Batch [  10 /  157]\n",
      "Batch [  11 /  157]\n",
      "Batch [  12 /  157]\n",
      "Batch [  13 /  157]\n",
      "Batch [  14 /  157]\n",
      "Batch [  15 /  157]\n",
      "Batch [  16 /  157]\n",
      "Batch [  17 /  157]\n",
      "Batch [  18 /  157]\n",
      "Batch [  19 /  157]\n",
      "Batch [  20 /  157]\n",
      "Batch [  21 /  157]\n",
      "Batch [  22 /  157]\n",
      "Batch [  23 /  157]\n",
      "Batch [  24 /  157]\n",
      "Batch [  25 /  157]\n",
      "Batch [  26 /  157]\n",
      "Batch [  27 /  157]\n",
      "Batch [  28 /  157]\n",
      "Batch [  29 /  157]\n",
      "Batch [  30 /  157]\n",
      "Batch [  31 /  157]\n",
      "Batch [  32 /  157]\n",
      "Batch [  33 /  157]\n",
      "Batch [  34 /  157]\n",
      "Batch [  35 /  157]\n",
      "Batch [  36 /  157]\n",
      "Batch [  37 /  157]\n",
      "Batch [  38 /  157]\n",
      "Batch [  39 /  157]\n",
      "Batch [  40 /  157]\n",
      "Batch [  41 /  157]\n",
      "Batch [  42 /  157]\n",
      "Batch [  43 /  157]\n",
      "Batch [  44 /  157]\n",
      "Batch [  45 /  157]\n",
      "Batch [  46 /  157]\n",
      "Batch [  47 /  157]\n",
      "Batch [  48 /  157]\n",
      "Batch [  49 /  157]\n",
      "Batch [  50 /  157]\n",
      "Batch [  51 /  157]\n",
      "Batch [  52 /  157]\n",
      "Batch [  53 /  157]\n",
      "Batch [  54 /  157]\n",
      "Batch [  55 /  157]\n",
      "Batch [  56 /  157]\n",
      "Batch [  57 /  157]\n",
      "Batch [  58 /  157]\n",
      "Batch [  59 /  157]\n",
      "Batch [  60 /  157]\n",
      "Batch [  61 /  157]\n",
      "Batch [  62 /  157]\n",
      "Batch [  63 /  157]\n",
      "Batch [  64 /  157]\n",
      "Batch [  65 /  157]\n",
      "Batch [  66 /  157]\n",
      "Batch [  67 /  157]\n",
      "Batch [  68 /  157]\n",
      "Batch [  69 /  157]\n",
      "Batch [  70 /  157]\n",
      "Batch [  71 /  157]\n",
      "Batch [  72 /  157]\n",
      "Batch [  73 /  157]\n",
      "Batch [  74 /  157]\n",
      "Batch [  75 /  157]\n",
      "Batch [  76 /  157]\n",
      "Batch [  77 /  157]\n",
      "Batch [  78 /  157]\n",
      "Batch [  79 /  157]\n",
      "Batch [  80 /  157]\n",
      "Batch [  81 /  157]\n",
      "Batch [  82 /  157]\n",
      "Batch [  83 /  157]\n",
      "Batch [  84 /  157]\n",
      "Batch [  85 /  157]\n",
      "Batch [  86 /  157]\n",
      "Batch [  87 /  157]\n",
      "Batch [  88 /  157]\n",
      "Batch [  89 /  157]\n",
      "Batch [  90 /  157]\n",
      "Batch [  91 /  157]\n",
      "Batch [  92 /  157]\n",
      "Batch [  93 /  157]\n",
      "Batch [  94 /  157]\n",
      "Batch [  95 /  157]\n",
      "Batch [  96 /  157]\n",
      "Batch [  97 /  157]\n",
      "Batch [  98 /  157]\n",
      "Batch [  99 /  157]\n",
      "Batch [ 100 /  157]\n",
      "Batch [ 101 /  157]\n",
      "Batch [ 102 /  157]\n",
      "Batch [ 103 /  157]\n",
      "Batch [ 104 /  157]\n",
      "Batch [ 105 /  157]\n",
      "Batch [ 106 /  157]\n",
      "Batch [ 107 /  157]\n",
      "Batch [ 108 /  157]\n",
      "Batch [ 109 /  157]\n",
      "Batch [ 110 /  157]\n",
      "Batch [ 111 /  157]\n",
      "Batch [ 112 /  157]\n",
      "Batch [ 113 /  157]\n",
      "Batch [ 114 /  157]\n",
      "Batch [ 115 /  157]\n",
      "Batch [ 116 /  157]\n",
      "Batch [ 117 /  157]\n",
      "Batch [ 118 /  157]\n",
      "Batch [ 119 /  157]\n",
      "Batch [ 120 /  157]\n",
      "Batch [ 121 /  157]\n",
      "Batch [ 122 /  157]\n",
      "Batch [ 123 /  157]\n",
      "Batch [ 124 /  157]\n",
      "Batch [ 125 /  157]\n",
      "Batch [ 126 /  157]\n",
      "Batch [ 127 /  157]\n",
      "Batch [ 128 /  157]\n",
      "Batch [ 129 /  157]\n",
      "Batch [ 130 /  157]\n",
      "Batch [ 131 /  157]\n",
      "Batch [ 132 /  157]\n",
      "Batch [ 133 /  157]\n",
      "Batch [ 134 /  157]\n",
      "Batch [ 135 /  157]\n",
      "Batch [ 136 /  157]\n",
      "Batch [ 137 /  157]\n",
      "Batch [ 138 /  157]\n",
      "Batch [ 139 /  157]\n",
      "Batch [ 140 /  157]\n",
      "Batch [ 141 /  157]\n",
      "Batch [ 142 /  157]\n",
      "Batch [ 143 /  157]\n",
      "Batch [ 144 /  157]\n",
      "Batch [ 145 /  157]\n",
      "Batch [ 146 /  157]\n",
      "Batch [ 147 /  157]\n",
      "Batch [ 148 /  157]\n",
      "Batch [ 149 /  157]\n",
      "Batch [ 150 /  157]\n",
      "Batch [ 151 /  157]\n",
      "Batch [ 152 /  157]\n",
      "Batch [ 153 /  157]\n",
      "Batch [ 154 /  157]\n",
      "Batch [ 155 /  157]\n",
      "Batch [ 156 /  157]\n",
      "Batch [ 157 /  157]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(valid_loader):\n",
    "        print('Batch [%4d / %4d]' % (i+1, len(valid_loader)))\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "        outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        all_preds += list(preds.cpu().numpy())\n",
    "        all_labels += list(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 965,    0,    0,    0,    5,    1,    6,    0,    0,    3],\n",
       "       [   3, 1054,    0,    0,   31,    3,   34,    7,    2,    1],\n",
       "       [   9,    2,  860,   47,   28,    4,    2,   57,    8,   15],\n",
       "       [   2,    0,    0,  832,    0,  157,    2,   10,    7,    0],\n",
       "       [   0,    0,    0,    0,  979,    0,    1,    2,    0,    0],\n",
       "       [   4,    0,    1,    1,    2,  875,    7,    2,    0,    0],\n",
       "       [   4,    1,    0,    0,   19,   10,  924,    0,    0,    0],\n",
       "       [   0,    0,    0,    1,   12,    1,    0, 1012,    1,    1],\n",
       "       [  32,    4,    0,   14,   32,  108,   25,   18,  721,   20],\n",
       "       [   0,    1,    0,    0,  128,   29,    0,   49,    0,  802]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds);\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# function from https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot_confusion_matrix(cm, list(classes), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
